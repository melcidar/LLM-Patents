{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410fc3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae6a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "server = os.getenv(\"DB_SERVER\")\n",
    "database = os.getenv(\"DB_NAME\")\n",
    "\n",
    "connection_string = (\n",
    "    'mssql+pyodbc:///?odbc_connect='\n",
    "    f'DRIVER={{ODBC Driver 18 for SQL Server}};'\n",
    "    f'SERVER={server};'\n",
    "    f'DATABASE={database};'\n",
    "    'Trusted_Connection=yes;'\n",
    "    'TrustServerCertificate=yes;'\n",
    ")\n",
    "\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2aca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = None\n",
    "\n",
    "def init_model():\n",
    "    global _model\n",
    "    _model = SentenceTransformer(\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34675540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_claim(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    text = re.sub(r'<.*?>', '', text) #removing html\n",
    "    text = re.sub(r'the present invention.*?\\.', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed406249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_claims(claims):\n",
    "    global _model\n",
    "    return _model.encode(claims, batch_size=256)\n",
    "\n",
    "def process_batch_parallel(df):\n",
    "    df['cleaned_claim'] = df['claim_text'].apply(clean_claim)\n",
    "\n",
    "    num_cores = min(cpu_count(), 16)\n",
    "    chunks = np.array_split(df['cleaned_claim'].tolist(), num_cores)\n",
    "\n",
    "    with Pool(processes=num_cores, initializer=init_model) as pool:\n",
    "        results = list(tqdm(pool.imap(encode_claims, chunks), total=len(chunks), desc=\"Embedding chunks\"))\n",
    "\n",
    "    all_embeddings = np.vstack(results).astype('float32')\n",
    "\n",
    "    return df[['patent_id', 'cleaned_claim']], all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73807f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding chunks:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "    batch_size = 50000\n",
    "    offset = 0\n",
    "    batch_num = 0\n",
    "\n",
    "    # Use engine.connect() to control transactions manually\n",
    "    with engine.connect() as conn:\n",
    "        while True:\n",
    "            try:\n",
    "                # Load one batch\n",
    "                query = f\"\"\"\n",
    "                    SELECT patent_id, claim_text\n",
    "                    FROM independent_claims_sample\n",
    "                    ORDER BY patent_id\n",
    "                    OFFSET {offset} ROWS\n",
    "                    FETCH NEXT {batch_size} ROWS ONLY\n",
    "                \"\"\"\n",
    "                df = pd.read_sql(query, conn)\n",
    "\n",
    "                if df.empty:\n",
    "                    print(\"✅ Done! No more rows.\")\n",
    "                    break\n",
    "\n",
    "                # Process the batch (clean + embed)\n",
    "                meta_df, embed_matrix = process_batch_parallel(df)\n",
    "\n",
    "                # Save outputs\n",
    "                meta_df.to_csv(f\"output/metadata_batch_{batch_num}.csv\", index=False)\n",
    "                np.save(f\"output/embeddings_batch_{batch_num}.npy\", embed_matrix)\n",
    "\n",
    "                print(f\"✅ Batch {batch_num} saved. Rows: {len(df)}\")\n",
    "\n",
    "                # Update offset\n",
    "                offset += batch_size\n",
    "                batch_num += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error at batch {batch_num} (offset {offset}): {e}\")\n",
    "                conn.rollback()\n",
    "                break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a3a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
