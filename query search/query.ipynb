{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96a3e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\OneDrive - Association Digital Fabrication Laboratory\\Desktop\\Patents-code\\LLM-Patents\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f1a779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2829"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "import gc\n",
    "\n",
    "# ❌ Step 1: Delete the old index if it exists\n",
    "try:\n",
    "    del index  # or whatever your variable is called\n",
    "except NameError:\n",
    "    pass  # index wasn't defined\n",
    "\n",
    "# 🧹 Step 2: Force garbage collection\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b694908",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"E:\\\\Meliha-Patenti\\\\index\\\\faiss_index_ivf_cosine.bin\")\n",
    "#index = faiss.read_index(\"E:\\\\Meliha-Patenti\\\\index\\\\faiss_index_ivf_l2.bin\")\n",
    "metadata = pd.read_csv(\"E:\\\\Meliha-Patenti\\\\metadata_all.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d311d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\".\\\\local_minilm_l6_v2\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483ff023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Retrieval done. Check 'found itself (Y/N)' column in 'check1_with_retrieved.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"check1.csv\")\n",
    "\n",
    "# Set top-k\n",
    "k = 10\n",
    "\n",
    "# Assume model, index, metadata are already loaded\n",
    "retrieved_ids = []\n",
    "found_itself_flags = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    claim = row['claim']\n",
    "    true_patent_id = str(row['patent_id']).strip()\n",
    "\n",
    "    if pd.isna(claim) or not claim.strip():\n",
    "        retrieved_ids.append(\"\")\n",
    "        found_itself_flags.append(\"N\")\n",
    "        continue\n",
    "\n",
    "    # Increase initial search range to allow deduplication\n",
    "    search_k = k * 5  # e.g., 50 for top 10 unique\n",
    "    query_embedding = model.encode([claim], normalize_embeddings=True)\n",
    "    distances, indices = index.search(query_embedding.astype(\"float32\"), search_k)\n",
    "    \n",
    "    # Fetch patent_ids from metadata\n",
    "    top_k_metadata = metadata.iloc[indices[0]]\n",
    "    all_ids = top_k_metadata['patent_id'].astype(str)\n",
    "\n",
    "    # Deduplicate while preserving order, then take top-10 unique\n",
    "    unique_ids = list(dict.fromkeys(all_ids))[:k]\n",
    "    \n",
    "    retrieved_ids.append(\" | \".join(unique_ids))\n",
    "    found_itself_flags.append(\"Y\" if true_patent_id in unique_ids else \"N\")\n",
    "\n",
    "\n",
    "# Update the DataFrame\n",
    "df['top 10 retrieved patents'] = retrieved_ids\n",
    "df['found itself (Y/N)'] = found_itself_flags\n",
    "\n",
    "# Save output\n",
    "df.to_csv(\"check1_with_retrieved_cos.csv\", index=False)\n",
    "\n",
    "print(\"✅ Retrieval done. Check 'found itself (Y/N)' column in 'check1_with_retrieved.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7624d35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d656e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Interactive Patent Search\n",
      "Type your claim query. Type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Embed and search\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m query_embedding = \u001b[43mmodel\u001b[49m.encode([query], normalize_embeddings=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     17\u001b[39m distances, indices = index.search(query_embedding.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m), k)\n\u001b[32m     18\u001b[39m top_k_metadata = metadata.iloc[indices[\u001b[32m0\u001b[39m]]\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "k = 10  # top-k results per query\n",
    "\n",
    "print(\"\\n🔍 Interactive Patent Search\")\n",
    "print(\"Type your claim query. Type 'exit' to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"📝 Enter your patent claim:\\n> \").strip()\n",
    "    \n",
    "    if query.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"👋 Exiting search.\")\n",
    "        break\n",
    "    if not query:\n",
    "        continue\n",
    "\n",
    "    # Embed and search\n",
    "    query_embedding = model.encode([query], normalize_embeddings=True)\n",
    "    distances, indices = index.search(query_embedding.astype(\"float32\"), k)\n",
    "    top_k_metadata = metadata.iloc[indices[0]]\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n📄 Top-k Results:\")\n",
    "    for rank, (row, dist) in enumerate(zip(top_k_metadata.itertuples(index=False), distances[0]), 1):\n",
    "        print(f\"\\nRank {rank}\")\n",
    "        print(f\"Distance: {dist:.4f}\")\n",
    "        print(f\"Patent ID: {row.patent_id}\")\n",
    "        print(f\"Claim: {row.cleaned_claim}\")  # adjust column name if needed\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(\"\\n🌟 You can now enter another query or type 'exit' to stop.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5814d213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (patent-env)",
   "language": "python",
   "name": "patent-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
