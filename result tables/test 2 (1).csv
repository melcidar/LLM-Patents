Publication Number,Application Number,Title,Abstract,First Claim
US8379950,US13/039172,"Medical image processing","A computer-implemented method of detecting an object in a three-dimensional medical image comprises determining the values of a plurality of features at each voxel in at least a portion of the medical image. Each feature characterises a respective property of the medical image at a particular voxel. The likelihood probability distribution of each feature is calculated based on the values of the features and prior medical knowledge. A probability map is generated by using Bayes' law to combine the likelihood probability distributions, and the probability map is analysed to detect an object.","A method for detecting an object in a three-dimensional medical image, comprising:
determining, by a processing device, from data representing the three-dimensional medical image, for each voxel in a portion of the three-dimensional medical image, values of a plurality of features at the voxel, wherein each feature at the voxel characterizes a respective property of the three-dimensional medical image at the voxel;
calculating, by the processing device, a likelihood probability distribution of each feature based on the determined values of the feature and a parameter value derived from training data;
generating, by the processing device, a probability map that indicates a probability of each voxel in the portion of the three-dimensional medical image containing an object to be detected, wherein said generating a probability map includes combining, using Bayes' law, the likelihood probability distributions of the plurality of features at each respective voxel of the portion of the three-dimensional medical image;
detecting, by the processing device, the object in the portion of the three-dimensional medical image based on the probability map; and
outputting, by the processing device, an indication of the detected object.
"
US20090010508,US12/204375,"Medical image processing apparatus and medical image processing method","A medical image processing apparatus of the present invention has a three-dimensional model estimating section for estimating, based on an inputted two-dimensional image of an image of a living tissue within a body cavity, a three-dimensional model of the living tissue, a shape feature value calculating section for calculating shape feature values of respective voxels included in the three-dimensional model of the living tissue, a three-dimensional shape extracting section for extracting a first voxel group whose three-dimensional model has been estimated as a predetermined shape, in the respective voxels included in the three-dimensional model of the living tissue, based on the shape feature values, and a protruding shape detecting section for detecting the first voxel group as a voxel group configuring a protruding shape in the three-dimensional model of the living tissue.","A medical image processing apparatus comprising:
a three-dimensional model estimating section for estimating, based on an inputted two-dimensional image of an image of a living tissue within a body cavity, a three-dimensional model of the living tissue;
a shape feature value calculating section for calculating shape feature values of respective voxels included in the three-dimensional model of the living tissue;
a three-dimensional shape extracting section for extracting a first voxel group whose three-dimensional model has been estimated as a predetermined shape, in the respective voxels included in the three-dimensional model of the living tissue, based on the shape feature values; and
a protruding shape detecting section for detecting the first voxel group as a voxel group configuring a protruding shape in the three-dimensional model of the living tissue.
"
US8086005,US12/204330,"Medical image processing apparatus and medical image processing method","A medical image processing apparatus of the present invention includes an edge extracting section that extracts edges of an inputted two-dimensional image, a three-dimensional-model estimating section that estimates a three-dimensional model on the basis of the two-dimensional image, a voxel extracting section that extracts, on the basis of positions of respective voxels, where the edges are present, a predetermined voxel group to be set as a calculation object of a shape feature value, a shape-feature-value calculating section that calculates the shape feature value for at least a part of voxels among the predetermined voxel group, a three-dimensional-shape extracting section that extracts a voxel group, a three-dimensional model of which is estimated as a predetermined shape, on the basis of the shape feature value, and a tuberal-shape detecting section that detects the voxel group as a voxel group forming a tuberal shape in the three-dimensional model of the living tissue.","A medical image processing apparatus comprising:
an edge extracting section that extracts, on the basis of a two-dimensional image of an image of a living tissue in a body cavity inputted from a medical image pickup apparatus, edges of the two-dimensional image;
a three-dimensional-model estimating section that estimates a three-dimensional model of the living tissue on the basis of the two-dimensional image;
a voxel extracting section that extracts, on the basis of positions of respective voxels, where the edges are present, estimated as a part of the three-dimensional model, a predetermined voxel group to be set as a calculation object of a shape feature value;
a shape-feature-value calculating section that calculates the shape feature value for at least a part of voxels among the predetermined voxel group extracted by the voxel extracting section; and
a tuberal-shape detecting section that extracts, on the basis of the shape feature value, a voxel group, a three-dimensional model of which is estimated as a predetermined shape, among at least the part of voxels and detects the voxel group as a voxel group forming a tuberal shape in the three-dimensional model of the living tissue.
"
US8165367,US12/204375,"Medical image processing apparatus and medical image processing method having three-dimensional model estimating","A medical image processing apparatus of the present invention has a three-dimensional model estimating section for estimating, based on an inputted two-dimensional image of an image of a living tissue within a body cavity, a three-dimensional model of the living tissue, a shape feature value calculating section for calculating shape feature values of respective voxels included in the three-dimensional model of the living tissue, a three-dimensional shape extracting section for extracting a first voxel group whose three-dimensional model has been estimated as a predetermined shape, in the respective voxels included in the three-dimensional model of the living tissue, based on the shape feature values, and a protruding shape detecting section for detecting the first voxel group as a voxel group configuring a protruding shape in the three-dimensional model of the living tissue.","A medical image processing apparatus comprising:
a three-dimensional model estimating section for estimating, based on an inputted two-dimensional image of an image of a living tissue within a body cavity, a three-dimensional model of the living tissue;
a shape feature value calculating section for calculating shape feature values of respective voxels included in the three-dimensional model of the living tissue;
a three-dimensional shape extracting section for extracting a first voxel group whose three-dimensional model has been estimated as a predetermined shape, in the respective voxels included in the three-dimensional model of the living tissue, based on the shape feature values; and
a protruding shape detecting section for detecting the first voxel group as a voxel group configuring a protruding shape in the three-dimensional model of the living tissue.
"
US20210233240,US17/094984,"Device and method for detecting clinically important objects in medical images with distance-based decision stratification","A method for performing a computer-aided diagnosis (CAD) includes: acquiring a medical image set; generating a three-dimensional (3D) tumor distance map corresponding to the medical image set, each voxel of the tumor distance map representing a distance from the voxel to a nearest boundary of a primary tumor present in the medical image set; and performing neural-network processing of the medical image set to generate a predicted probability map to predict presence and locations of oncology significant lymph nodes (OSLNs) in the medical image set, wherein voxels in the medical image set are stratified and processed according to the tumor distance map.","A method for performing a computer-aided diagnosis (CAD), comprising:
acquiring a medical image set;
generating a three-dimensional (3D) tumor distance map corresponding to the medical image set, each voxel of the tumor distance map representing a distance from the voxel to a nearest boundary of a primary tumor present in the medical image set; and
performing neural-network processing of the medical image set to generate a predicted probability map to predict presence and locations of oncology significant lymph nodes (OSLNs) in the medical image set, wherein voxels in the medical image set are stratified and processed according to the tumor distance map.
"
US8121369,US12/652321,"Medical image processing apparatus and medical image processing method","The medical image processing apparatus of the present invention includes: a three-dimensional model estimating section that estimates a three-dimensional model based on a two-dimensional image; a local region setting section that sets a plurality of local regions around a target pixel in the two-dimensional image; a shape feature value calculating section that uses three-dimensional coordinate data corresponding to the plurality of local regions and calculates shape feature values of respective voxels corresponding to the target pixel; a shape feature value selecting section that selects, as a shape feature value of a voxel corresponding to the target pixel, a shape feature value calculated according to one local region including an optimum three-dimensional coordinate data amount among the plurality of shape feature values; and an elevated shape detecting section that detects an elevated shape existing in the two-dimensional image based on a selection result of the shape feature value selecting section.","A medical image processing apparatus, comprising:
a three-dimensional model estimating section that estimates a three-dimensional model of living tissue based on a two-dimensional image of an image of the living tissue inputted from a medical image pickup apparatus;
a local region setting section that sets a plurality of local regions around a target pixel in the two-dimensional image;
a shape feature value calculating section that uses three-dimensional coordinate data corresponding to each of the plurality of local regions and calculates shape feature values of respective voxels corresponding to the target pixel based on the three-dimensional model of the living tissue estimated by the three-dimensional model estimating section;
a shape feature value selecting section that selects, as an optimum shape feature value of a voxel corresponding to the target pixel, a shape feature value calculated according to one local region including an optimum three-dimensional coordinate data amount among the plurality of shape feature values calculated according to the plurality of local regions; and
an elevated shape detecting section that detects an elevated shape existing in the two-dimensional image based on a selection result of the shape feature value selecting section.
"
US20110216951,US13/039172,"Medical image processing","A computer-implemented method of detecting an object in a three-dimensional medical image comprises determining the values of a plurality of features at each voxel in at least a portion of the medical image. Each feature characterises a respective property of the medical image at a particular voxel. The likelihood probability distribution of each feature is calculated based on the values of the features and prior medical knowledge. A probability map is generated by using Bayes' law to combine the likelihood probability distributions, and the probability map is analysed to detect an object.","A method for detecting an object in a three-dimensional medical image, comprising:
determining, by a processing device, from data representing the three-dimensional medical image, for each voxel in a portion of the three-dimensional medical image, values of a plurality of features at the voxel, wherein each feature at the voxel characterizes a respective property of the three-dimensional medical image at the voxel;
calculating, by the processing device, a likelihood probability distribution of each feature based on the determined values of the feature and a parameter value derived from training data;
generating, by the processing device, a probability map that indicates a probability of each voxel in the portion of the three-dimensional medical image containing an object to be detected, wherein said generating a probability map includes combining, using Bayes' law, the likelihood probability distributions of the plurality of features at each respective voxel of the portion of the three-dimensional medical image;
detecting, by the processing device, the object in the portion of the three-dimensional medical image based on the probability map; and
outputting, by the processing device, an indication of the detected object.
"
US20120189176,US13/305495,"Method, system, software and medium for advanced intelligent image analysis and display of medical images and information","Computerized interpretation of medical images for quantitative analysis of multi-modality breast images including analysis of FFDM, 2D/3D ultrasound, MRI, or other breast imaging methods. Real-time characterization of tumors and background tissue, and calculation of image-based biomarkers is provided for breast cancer detection, diagnosis, prognosis, risk assessment, and therapy response. Analysis includes lesion segmentation, and extraction of relevant characteristics (textural/morphological/kinetic features) from lesion-based or voxel-based analyses. Combinations of characteristics in several classification tasks using artificial intelligence is provided. Output in terms of 1D, 2D or 3D distributions in which an unknown case is identified relative to calculations on known or unlabeled cases, which can go through a dimension-reduction technique. Output to 3D shows relationships of the unknown case to a cloud of known or unlabeled cases, in which the cloud demonstrates the structure of the population of patients with and without the disease.","A tangible computer-readable medium storing thereon executable instructions, that when executed by a computer, cause the computer to execute a process for determining a probability of a disease state of a patient, the process comprising:
obtaining medical data including at least one of a medical image, medical image data, and data representative of a clinical examination of the patient, the medical data including data points for a lesion which are spatially and temporally indexed;
reducing the spatially and temporally indexed data points to remove the temporal indexing and to obtain a kinetic curve for each data point;
extracting kinetic features of the lesion from each kinetic curve; and
displaying the extracted kinetic features.
"
US20240078669,US18/497912,"System and methods for inferring thickness of object classes of interest in two-dimensional medical images using deep neural networks","Methods and systems are provided for inferring thickness and volume of one or more object classes of interest in two-dimensional (2D) medical images, using deep neural networks. In an exemplary embodiment, a thickness of an object class of interest may be inferred by acquiring a 2D medical image, extracting features from the 2D medical image, mapping the features to a segmentation mask for an object class of interest using a first convolutional neural network (CNN), mapping the features to a thickness mask for the object class of interest using a second CNN, wherein the thickness mask indicates a thickness of the object class of interest at each pixel of a plurality of pixels of the 2D medical image; and determining a volume of the object class of interest based on the thickness mask and the segmentation mask.","A medical imaging system comprising:
an imaging device;
a display device;
a memory, storing:
a feature extractor;
a first trained convolutional neural network (CNN);
a second trained CNN; and
instructions;
a processor communicably coupled to the imaging device, the display device, and the memory, and when executing the instructions, configured to:
acquire a two-dimensional (2D) medical image of an anatomical region of an imaging subject via the imaging device;
extract features from the 2D medical image using the feature extractor;
map the features to a segmentation mask for an object class of interest using the first trained CNN;
map the features to a thickness mask for the object class of interest using the second trained CNN, wherein the thickness mask indicates a thickness of the object class of interest at each pixel of a plurality of pixels of the 2D medical image;
apply the segmentation mask to the thickness mask to produce a segmented thickness mask; and
display the segmented thickness mask via the display device.
"
US12361553,US18/497912,"System and methods for inferring thickness of object classes of interest in two-dimensional medical images using deep neural networks","Methods and systems are provided for inferring thickness and volume of one or more object classes of interest in two-dimensional (2D) medical images, using deep neural networks. In an exemplary embodiment, a thickness of an object class of interest may be inferred by acquiring a 2D medical image, extracting features from the 2D medical image, mapping the features to a segmentation mask for an object class of interest using a first convolutional neural network (CNN), mapping the features to a thickness mask for the object class of interest using a second CNN, wherein the thickness mask indicates a thickness of the object class of interest at each pixel of a plurality of pixels of the 2D medical image; and determining a volume of the object class of interest based on the thickness mask and the segmentation mask.","A medical imaging system comprising:
an imaging device;
a display device;
a memory, storing:
a feature extractor;
a first trained convolutional neural network (CNN);
a second trained CNN; and
instructions;
a processor communicably coupled to the imaging device, the display device, and the memory, and when executing the instructions, configured to:
acquire a two-dimensional (2D) medical image of an anatomical region of an imaging subject via the imaging device;
extract features from the 2D medical image using the feature extractor;
map the features to a segmentation mask for an object class of interest using the first trained CNN;
map the features to a thickness mask for the object class of interest using the second trained CNN, wherein the thickness mask indicates a thickness of the object class of interest at each pixel of a plurality of pixels of the 2D medical image;
apply the segmentation mask to the thickness mask to produce a segmented thickness mask; and
display the segmented thickness mask via the display device, wherein the segmented thickness mask is displayed as a thickness heat-map for the object class of interest overlaid on the 2D medical image.
"
US6826297,US09/860867,"Displaying three-dimensional medical images","Multiple objects having the same physical property within a subject are displayed as distinct three-dimensional images in one or more views. Projection data obtained by scanning the subject with electromagnetic radiation are used to create a spatial distribution of absorption values for the subject that is displayed as an image on an image display unit. The spatial distribution is also stored as a series of voxels representing a three-dimensional image of the subject. Particular spatial regions within the image are defined as objects, with each object comprising a set of voxels. The objects are grouped into one or more views using a set selection panel on the image display unit. A density, gradient and color for each object in a view are determined based on properties input through the a series of object property setting panels on the image display unit. Each object in a particular view is associated with one of the property setting panels. A relationship between degrees of opacity and values for the voxels in an object is defined in the property setting panel for the object and used to determine the density. The density, gradient and color for the objects in a view are stored as a parameter set in memory and optionally, on a non-volatile medium for subsequent retrieval. A volume rendering process applies the data in the parameter sets to the stored voxels to create one or more views of the three-dimensional image. A viewpoint parameter provides a common viewpoint for displaying multiple views simultaneously in different areas of a display.","An apparatus for displaying three-dimensional medical images of a subject comprising:
means for storing three-dimensional voxel data representing a three-dimensional image of the subject with voxel values corresponding to a physical property of the subject; 
means for defining a plurality of object parameter-sets from object parameters for a plurality of objects in the three-dimensional image, each object parameter specifying a spatial region, opacity and color of a corresponding object; 
means for storing the plurality of object parameter-sets, each object parameter-set specifying a view of the three-dimensional image; 
means for creating a plurality of view data of the three-dimensional image by applying the plurality of object parameter-sets to the voxel values; 
means for creating a plurality of views of the three-dimensional image by applying projection-process parameters to the plurality of view data; and 
means for displaying the plurality of views of the three-dimensional image on an image display unit. 
"
US20060104406,US10/526235,"Method and arrangement for medical x-ray imaging and reconstruction from sparse data","The invention relates to a medical X-ray device 5 arrangement for producing three-dimensional information of an object 4 in a medical X-ray imaging medical X-ray device arrangement comprising an X-ray source 2 for X-radiating the object from different directions and a detector 6 for detecting the X-radiation to form projection data of the object 4. The medical X-ray device 5 arrangement comprises: means 15 for modelling the object 4 mathematically independently of X-ray imaging and means 15 for utilizing said projection data and said mathematical modelling of the object in Bayesian inversion based on Bayes' formula     p ⁢  (  ⁢ x ⁢   m )   =      p pr  ⁡  ( x )   ⁢  p ( m   ⁢ x  )   p ⁡  ( m )       to produce three-dimensional information of the object, the prior distribution ppr(x) representing mathematical modelling of the object, the object image vector x, which comprise values of the X-ray attenuation coefficient inside the object, m representing projection data, the likelihood distribution p(m","A method for producing three-dimensional information of an object (4) in medical X-ray imaging, characterized in that 
the object is modelled mathematically independently of X-ray imaging, 
the object is X-radiated from at least two different directions and the said X-radiation is detected to form projection data of the object (4), 
and said projection data and said mathematical modelling of the object are utilized in Bayesian inversion based on Bayes' formula 
 
 p  ( x | m ) = p pr  ( x )  p  ( m | x ) p  ( m )  (see pdf for full equation)
to produce three-dimensional information of the object, the prior distribution ppr(x) representing mathematical modelling of the object, x representing the object image vector, which comprises values of the X-ray attenuation coefficient inside the object, m representing projection data, the likelihood distribution p(m|x) representing the X-radiation attenuation model between the object Image vector x and projection data m, p(m) being a normalization constant and the posteriori distribution p(x|m) representing the three-dimensional information of the object (4). 
"
US7269241,US10/526235,"Method and arrangement for medical x-ray imaging and reconstruction from sparse data","The invention relates to a medical X-ray device 5 arrangement for producing three-dimensional information of an object 4 in a medical X-ray imaging medical X-ray device arrangement comprising an X-ray source 2 for X-radiating the object from different directions and a detector 6 for detecting the X-radiation to form projection data of the object 4 . The medical X-ray device 5 arrangement comprises: means 15 for modelling the object 4 mathematically independently of X-ray imaging and means 15 for utilizing said projection data and said mathematical modelling of the object in Bayesian inversion based on Bayes' formula     p ⁢  (  ⁢ x ⁢   m )   =      p pr  ⁡  ( x )   ⁢  p ( m   ⁢ x  )   p ⁡  ( m )       to produce three-dimensional information of the object, the prior distribution ppr(x) representing mathematical modelling of the object, the object image vector x, which comprise values of the X-ray attenuation coefficient inside the object, m representing projection data, the likelihood distribution p(m","A method for producing three-dimensional information of an object in medical X-ray imaging, characterized in that
the object is modelled mathematically independently of X-ray imaging,
the object is X-radiated from at least two different directions and the said X-radiation is detected to form projection data of the object,
said projection data and said mathematical modelling of the object are utilized in Bayesian inversion based on Bayes' formula
 p  ( x | m ) = p pr  ( x )  p  ( m | x ) p  ( m )  (see pdf for full equation)
the prior distribution ppr(X) representing mathematical modelling of the object, x representing the object image vector, which comprises values of the X-ray attenuation coefficient inside the object, m representing projection data, the likelihood distribution p(m|x) representing the X-radiation attenuation model between the object image vector x and projection data m, p(m) being a normalization constant and the posteriori distribution p(x|m) representing the three-dimensional information of the object, and
three-dimensional medical X-ray imaging information of the object is produced.
"
US20100034443,US12/579681,"Medical image processing apparatus and medical image processing method","A medical image processing apparatus of the present invention includes an edge extraction portion that extracts an edge in a two-dimensional image of a living body tissue, a three-dimensional model estimation portion that estimates a three-dimensional model of the living body tissue, based on the two-dimensional image, a local region setting portion that sets a local region centered on a pixel of interest in the two-dimensional image, a determination portion that determines whether the local region is divided by at least part of the edge extracted a shape feature value calculation portion that calculates a shape feature value of the pixel of interest using predetermined three-dimensional coordinate data based on a result of determination by the determination portion, and a raised shape detection portion that detects a raised shape, based on a result of calculation by the shape feature value calculation portion.","A medical image processing apparatus comprising:
an edge extraction portion that extracts an edge in a two-dimensional image of a living body tissue inputted from a medical image pickup apparatus, based on the two-dimensional image;
a three-dimensional model estimation portion that estimates a three-dimensional model of the living body tissue, based on the two-dimensional image;
a local region setting portion that sets a local region centered on a pixel of interest in the two-dimensional image;
a determination portion that determines whether the local region is divided by at least part of the edge extracted by the edge extraction portion;
a shape feature value calculation portion that calculates a shape feature value of the pixel of interest using three-dimensional coordinate data corresponding to, of the local region, a region which is not divided by the edge extracted by the edge extraction portion and in which the pixel of interest is present, based on a result of determination by the determination portion; and
a raised shape detection portion that detects a raised shape based on a result of calculation by the shape feature value calculation portion.
"
US12020440,US17/310330,"Layer boundary evolution for macular optical coherence tomography segmentation","A device receives a two-dimensional (2-D) image that depicts a cross-sectional view of a retina that includes a macula comprised of layers and boundaries used to segment the layers. The device converts the 2-D image to a standardized format, determines features for voxels included in the 2-D image, and generates, by using a data model to process the features, probability maps that indicate likelihoods of the voxels being in positions within particular boundaries. The device analyzes the probability maps to determine an initial set of boundary positions and to generate directional vectors that point in directions based on values included in the set of probability maps, determines a final set of boundary positions by performing a layer boundary evolution technique using the directional vectors to refine the initial set of boundary positions, and provides data that identifies the final set of boundary positions for display via an interface.","A method, comprising:
receiving, by a device, a two-dimensional (2-D) image that depicts a cross-sectional view of a retina of an eye,
wherein the retina includes a macula that includes:
layers, and
boundaries that are used to segment the layers;
converting, by the device, the 2-D image to a standardized format;
determining, by the device, a set of features for voxels included in the 2-D image;
generating, by the device and by using a data model to process the set of features, a set of probability maps that indicate likelihoods of the voxels being in positions within particular boundaries,
wherein the data model has been trained by using one or more machine learning techniques to analyze a labeled set of 2-D images that depict retinas of eyes;
determining, by the device and by analyzing the set of probability maps, an initial set of boundary positions for the boundaries;
generating, by the device and by analyzing the set of probability maps, a set of directional vectors that point in directions that are based on values included in the set of probability maps;
determining, by the device and by performing a layer boundary evolution (LBE) technique, a final set of boundary positions for the boundaries,
wherein performing the LBE technique includes using the set of directional vectors to refine the initial set of boundary positions,
wherein determining the final set of boundary positions comprises referencing a set of rules to determine, based on the set of directional vectors, a manner in which to refine the initial set of boundary positions, and
wherein the set of rules comprises:
a first rule indicating that a specific boundary position is to be added to the final set of boundary positions if two vertically-aligned directional vectors are pointed toward each other in opposite directions,
a second rule indicating that the specific boundary position is not to be added to the final set of boundary positions if the two vertically-aligned directional vectors are pointed in a uniform direction,
wherein the uniform direction is used to identify a next boundary position that is to be considered for the final set of boundary positions, or
a third rule indicating that a smoothing technique is to be used when considering the specific boundary position if the two vertically-aligned directional vectors are pointed away from each other in opposite directions; and
providing, by the device, data that identifies the final set of boundary positions for display via an interface.
"
US11488302,US16/985966,"Object recognition method and device, and storage medium","An object recognition method is performed at an electronic device. The method includes: pre-processing a target image, to obtain a pre-processed image, the pre-processed image including three-dimensional image information of a target region of a to-be-detected object, processing the pre-processed image by using a target data model, to obtain a target probability, the target probability being used for representing a probability that an abnormality appears in a target object in the target region of the to-be-detected object; and determining a recognition result of the target region of the to-be-detected object according to the target probability, the recognition result being used for indicating the probability that the abnormality appears in the target region of the to-be-detected object. The object recognition method can effectively improve accuracy of object recognition and avoid a case of incorrect recognition.","An object recognition method, applied to an electronic device having a processor and memory storing a plurality of operations to be executed by the processor, the method comprising:
pre-processing a target image to obtain a pre-processed image, the pre-processed image comprising three-dimensional image information of a target region of a to-be-detected object;
processing the pre-processed image using a target data model to obtain a target object in the target region of the to-be-detected object, wherein:
the target data model is obtained by training a convolutional neural network using a plurality of sets of data, each of the plurality of sets of data comprising three-dimensional image information of a target region of a sample object and indication information corresponding to the three-dimensional image information, the indication information being used for indicating whether an abnormality appears in the target region of the sample object, and the three-dimensional image information of the target region of the sample object being at least used for representing the target object in the target region of the sample object; and
the processing includes:
processing the pre-processed image using a first residual block and a pooling layer in the target data model, to extract a high-level semantic feature contained in the pre-processed image;
processing the high-level semantic feature using a second residual block and a deconvolution layer in the target data model, to recover a resolution feature of the target object; and
identifying the target object in the target region of the to-be-detected object and determining a probability that the target object constitutes an abnormality according to the resolution feature.
"
US20050105694,US10/813563,"Method and arrangement for medical x-ray imaging","A medical X-ray device 5 arrangement for producing three-dimensional information of an object 4 in a medical X-ray imaging comprises an X-ray source 2 for X-radiating the object from at least two different directions; a detector 6 for detecting the X-radiation to form projection data of the object 4 ; a computational device 15 for modelling the object 4 mathematically utilizing the projection data to solve the imaging geometry and/or the motion of the object, where the solving concerns either some or all parts of the imaging geometry and/or the motion of the object. The computational device 15 utilizes said projection data and said mathematical modelling of the object in Bayesian inversion based on Bayes' formula     p ⁡  (  x ,  theta ❘ m   )   =     p pr  ⁡  ( theta )   ⁢   p pr  ⁡  ( x )   ⁢  p ⁡  (   m ❘ x  , theta  )     p ⁡  ( m )       to produce three-dimensional information of the object.","A method for producing three-dimensional information of an object (4) in medical X-ray imaging, characterized in that 
the object is X-radiated from at least two different directions and the said X-radiation is detected to form projection data of the object (4) 
the object is modelled mathematically utilizing the projection data to solve the imaging geometry and/or the motion of the object, where the solving concerns either some or all parts of the imaging geometry and/or the motion of the object. 
and said projection data and said mathematical modelling of the object are utilized in Bayesian inversion based on Bayes' formula 
 
 p  ( x ,  | m ) = p pr  (  )  p pr  ( x )  p  ( m | x ,  ) p  ( m )  (see pdf for full equation)
to produce three-dimensional information of the object, the prior distribution ppr() representing the prior knowledge of the imaging geometry and/or the motion of the object (4), the prior distribution ppr(x) representing mathematical modelling of the object, x representing the object image vector, which comprises values of the X-ray attenuation coefficient inside the object, representing the parameter vector of the imaging geometry and/or the motion of the object (4), m representing projection data, the likelihood distribution p(m|x,) representing the X-radiation attenuation model between the object image vector x, geometry parameter vector , and projection data m, p(m) being a normalization constant and the posteriori distribution p(x,|m) representing the three-dimensional information of the object (4) and the imaging geometry including the motion of the object. 
"
US7068752,US10/813563,"Method and arrangement for medical x-ray imaging","A medical X-ray device 5 arrangement for producing three-dimensional information of an object 4 in a medical X-ray imaging comprises an X-ray source 2 for X-radiating the object from at least two different directions; a detector 6 for detecting the X-radiation to form projection data of the object 4; a computational device 15 for modelling the object 4 mathematically utilizing the projection data to solve the imaging geometry and/or the motion of the object, where the solving concerns either some or all parts of the imaging geometry and/or the motion of the object. The computational device 15 utilizes said projection data and said mathematical modelling of the object in Bayesian inversion based on Bayes' formula     p ⁡  (  x ,  theta ❘ m   )   =     p pr  ⁡  ( theta )   ⁢   p pr  ⁡  ( x )   ⁢  p ⁡  (   m ❘ x  , theta  )     p ⁡  ( m )       to produce three-dimensional information of the object.","A method for producing three-dimensional information of an object (4) in medical X-ray imaging, characterized in that
the object is X-radiated from at least two different directions and the said X-radiation is detected to form projection data of the object (4)
the object is modelled mathematically utilizing the projection data to solve the imaging geometry and/or the motion of the object, where the solving concerns either some or all parts of the imaging geometry and/or the motion of the object
and said projection data and said mathematical modelling of the object are utilized in Bayesian inversion based on Bayes' formula
 p  ( x ,  | m ) = p pr  (  )  p pr  ( x )  p  ( m | x ,  ) p  ( m )  (see pdf for full equation)
to produce three-dimensional information of the object, the prior distribution ppr() representing the prior knowledge of the imaging geometry and/or the motion of the object (4), the prior distribution ppr(x) representing mathematical modelling of the object, x representing the object image vector, which comprises values of the X-ray attenuation coefficient inside the object, representing the parameter vector of the imaging geometry and/or the motion of the object (4), m representing projection data, the likelihood distribution p(m|x,) representing the X-radiation attenuation model between the object image vector x, geometry parameter vector , and projection data m, p(m) being a normalization constant and the posteriori distribution p(x,|m) representing the three-dimensional information of the object (4) and the imaging geometry including the motion of the object.
"
US10902596,US16/165383,"Tomographic data analysis","Data from a tomographic scan (14) that provides three-dimensional information about a patient's brain comprises the steps of: filtering and re-sampling (21) the data to produce a three-dimensional image; performing registration (23) to align the three-dimensional image with a reference image (16), using 3-D rigid and/or non-rigid transformations; identifying (25) image features in the aligned image, to identify which voxels or regions of adjacent voxels correspond to image features that represent structures within the brain that are expected to be evident; classifying (26) each voxel within an identified image feature by a voxel score that corresponds to the difference between the attenuation of that voxel and the expected attenuation at that region of the brain; and deducing a cumulative score that combines the voxel scores from all the voxels of at least a region of the brain. This method can provide a medical professional with a rapid indication of the status of the brain tissue, which can be used to guide the selection of treatment to best improve the prospects for a patient, particularly a patient who has had an ischaemic stroke.","A computer-implemented method for deriving a score representative of extent and progression of ischemia in a patient's brain, by analysing data from a tomographic scan that provides three-dimensional information about the patient's brain, the method comprising the steps of:
processing the data to produce a three-dimensional image representative of the patient's brain;
performing registration to align the three-dimensional image with a reference image, using 3-D rigid and/or non-rigid transformations;
identifying regions in the aligned image that correspond to normal regions within a brain;
determining, from said aligned image, the attenuation of each of a plurality of first voxels or group of adjacent voxels within each identified region of the brain;
classifying each said first voxel or group of adjacent voxels within each identified region by a probability value that is derived from, and indicative of, a difference between the determined attenuation of a voxel or group of adjacent voxels and an expected attenuation of that voxel or group of adjacent voxels at that region of the brain, wherein said classifying in respect of each of said plurality of first voxels or group of adjacent voxels having a particular type of brain structure comprises determining, from the same said aligned image, the attenuation of a respective second voxel or group of voxels in a corresponding region on the opposite side of the brain having the same type of brain structure, comparing the determined attenuation of each said first voxel or group of adjacent voxels with the determined attenuation of a respective second voxel or grow of adjacent voxels to derive a value for the difference therebetween, and generating a respective voxel score comprising a said probability value indicative of said difference;
applying one or more probability values to each said identified region to generate a probability map of ischemic changes within the patient's brain, wherein each applied probability value is indicative of a strength of evidence of ischemia at a respective identified region; and
deducing a cumulative score that combines the probability values from all the voxels of at least an identified region of the patient's brain.
"
US11341639,US16/767785,"Three-dimensional medical image analysis method and system for identification of vertebral fractures","A machine-based learning method estimates a probability of bone fractures in a 3D image, more specifically vertebral fractures. The method and system utilizing such method utilize a data-driven computational model to learn 3D image features for classifying vertebra fractures. A three-dimensional medical image analysis system for predicting a presence of a vertebral fracture in a subject includes a 3D image processor for receiving and processing 3D image data of a 3D image of the subject, producing two or more sets of 3D voxels. Each of the sets of 3D voxels corresponds to an entirety of the 3D image and each of the sets of 3D voxels consists of equal 3D voxels of different dimensions. The system also includes a voxel classifier for assigning the 3D voxels one or more class probabilities each of the 3D voxels contains a fracture using a computational model, and a fracture probability estimator for estimating a probability of the presence of a vertebral fracture in the subject.","A three-dimensional medical image analysis system for predicting a presence of a vertebral fracture in a subject, comprising:
a 3D image processor for receiving and processing 3D image data of a 3D image of the subject, producing two or more sets of 3D voxels including a first set of 3D voxels and a second set of 3D voxels, each of the first set of 3D voxels and the second set of 3D voxels corresponding to an entirety of the 3D image, 3D voxels of the first set of 3D voxels each being of equal dimensions, 3D voxels of the second set of 3D voxels each being of equal dimensions, the 3D voxels of the first set of 3D voxels being of different dimensions than the 3D voxels of the second set of 3D voxels;
a voxel classifier for assigning the 3D voxels of the first set of 3D voxels and the 3D voxels of the second set of 3D voxels one or more class probabilities each of the 3D voxels contains a fracture using a computational model; and
a fracture probability estimator for estimating a probability of the presence of a vertebral fracture in the subject based on the one or more class probabilities of each the 3D voxels of the first set of 3D voxels and each of the 3D voxels of the second set of 3D voxels.
"
US20220358644,US17/726459,"Three-dimensional medical image analysis method and system for identification of vertebral fractures","A machine-based learning method estimates a probability of bone fractures in a 3D image, more specifically vertebral fractures. The method and system utilizing such method utilize a data-driven computational model to learn 3D image features for classifying vertebra fractures. A three-dimensional medical image analysis system for predicting a presence of a vertebral fracture in a subject includes a 3D image processor for receiving and processing 3D image data of a 3D image of the subject, producing two or more sets of 3D voxels. Each of the sets of 3D voxels corresponds to an entirety of the 3D image and each of the sets of 3D voxels consists of equal 3D voxels of different dimensions. The system also includes a voxel classifier for assigning the 3D voxels one or more class probabilities each of the 3D voxels contains a fracture using a computational model, and a fracture probability estimator for estimating a probability of the presence of a vertebral fracture in the subject.","A three-dimensional medical image analysis system for predicting a presence of a vertebral fracture in a subject, comprising:
a 3D image processor configured for receiving and processing 3D image data of a 3D image of the subject to produce a first set of voxels having a first resolution and a second set of voxels having a second resolution different from the first resolution;
a voxel classifier configured for:
processing the first set of voxels to generate a first output;
processing the second set of voxels to generate a second output; and
processing the first and second outputs together, and outputting a fracture class probability for each voxel of the first set of voxels and for each voxel of the second set of voxels; and
a fracture probability estimator for estimating a probability of a presence of a vertebral fracture in the subject based on the output fracture class probabilities.
"
US11710233,US17/726459,"Three-dimensional medical image analysis method and system for identification of vertebral fractures","A machine-based learning method estimates a probability of bone fractures in a 3D image, more specifically vertebral fractures. The method and system utilizing such method utilize a data-driven computational model to learn 3D image features for classifying vertebra fractures. A three-dimensional medical image analysis system for predicting a presence of a vertebral fracture in a subject includes a 3D image processor for receiving and processing 3D image data of a 3D image of the subject, producing two or more sets of 3D voxels. Each of the sets of 3D voxels corresponds to an entirety of the 3D image and each of the sets of 3D voxels consists of equal 3D voxels of different dimensions. The system also includes a voxel classifier for assigning the 3D voxels one or more class probabilities each of the 3D voxels contains a fracture using a computational model, and a fracture probability estimator for estimating a probability of the presence of a vertebral fracture in the subject.","A three-dimensional medical image analysis system for predicting a presence of a vertebral fracture in a subject, comprising:
a 3D image processor configured for receiving and processing 3D image data of a 3D image of the subject to produce a first set of voxels having a first resolution and a second set of voxels having a second resolution different from the first resolution;
a voxel classifier configured for:
processing the first set of voxels to generate a first output;
processing the second set of voxels to generate a second output; and
processing the first and second outputs together, and outputting a fracture class probability for each voxel of the first set of voxels and for each voxel of the second set of voxels; and
a fracture probability estimator for estimating a probability of a presence of a vertebral fracture in the subject based on the output fracture class probabilities.
"
US20090003671,US12/204330,"Medical image processing apparatus and medical image processing method","A medical image processing apparatus of the present invention includes an edge extracting section that extracts edges of an inputted two-dimensional image, a three-dimensional-model estimating section that estimates a three-dimensional model on the basis of the two-dimensional image, a voxel extracting section that extracts, on the basis of positions of respective voxels, where the edges are present, a predetermined voxel group to be set as a calculation object of a shape feature value, a shape-feature-value calculating section that calculates the shape feature value for at least a part of voxels among the predetermined voxel group, a three-dimensional-shape extracting section that extracts a voxel group, a three-dimensional model of which is estimated as a predetermined shape, on the basis of the shape feature value, and a tuberal-shape detecting section that detects the voxel group as a voxel group forming a tuberal shape in the three-dimensional model of the living tissue.","A medical image processing apparatus comprising:
an edge extracting section that extracts, on the basis of a two-dimensional image of an image of a living tissue in a body cavity inputted from a medical image pickup apparatus, edges of the two-dimensional image;
a three-dimensional-model estimating section that estimates a three-dimensional model of the living tissue on the basis of the two-dimensional image;
a voxel extracting section that extracts, on the basis of positions of respective voxels, where the edges are present, estimated as a part of the three-dimensional model, a predetermined voxel group to be set as a calculation object of a shape feature value;
a shape-feature-value calculating section that calculates the shape feature value for at least a part of voxels among the predetermined voxel group extracted by the voxel extracting section; and
a tuberal-shape detecting section that extracts, on the basis of the shape feature value, a voxel group, a three-dimensional model of which is estimated as a predetermined shape, among at least the part of voxels and detects the voxel group as a voxel group forming a tuberal shape in the three-dimensional model of the living tissue.
"
US20090079737,US12/238603,"Medical image processing apparatus and medical image processing method","A medical image processing apparatus of the invention comprises: a three-dimensional model estimating section that estimates a three-dimensional model of body tissues based on a two-dimensional image of an image of the body tissues inside a body cavity inputted from a medical image pickup apparatus; a voxel detecting section that detects one voxel existing on a nearest side in a view direction of the medical image pickup apparatus among the voxels included in the three-dimensional model; and a raised shape detecting section that acquires one curved surface including the one voxel to detect a position with gradient variation on the one curved surface and to determine whether or not body tissues with a locally raised shape exist in the position in the three-dimensional model.","A medical image processing apparatus comprising:
a three-dimensional model estimating section that estimates a three-dimensional model of body tissues based on a two-dimensional image of an image of the body tissues inside a body cavity inputted from a medical image pickup apparatus;
a voxel detecting section that detects one voxel existing on a nearest side in a view direction of the medical image pickup apparatus among voxels included in the three-dimensional model; and
a raised shape detecting section that acquires one curved surface including the one voxel to detect a position with gradient variation on the one curved surface and to determine whether or not body tissues with a locally raised shape exist in the position in the three-dimensional model.
"
US7830378,US12/238603,"Medical image processing apparatus and medical image processing method","A medical image processing apparatus of the invention comprises: a three-dimensional model estimating section that estimates a three-dimensional model of body tissues based on a two-dimensional image of an image of the body tissues inside a body cavity inputted from a medical image pickup apparatus; a voxel detecting section that detects one voxel existing on a nearest side in a view direction of the medical image pickup apparatus among the voxels included in the three-dimensional model; and a raised shape detecting section that acquires one curved surface including the one voxel to detect a position with gradient variation on the one curved surface and to determine whether or not body tissues with a locally raised shape exist in the position in the three-dimensional model.","A medical image processing apparatus comprising:
an image storage that stores a two-dimensional image of an image of body tissues inside a body cavity inputted from a medical image pickup apparatus;
a three-dimensional model estimating section that estimates a three-dimensional model of body tissues based on the two-dimensional image of the image of the body tissues inside the body cavity inputted from the medical image pickup apparatus;
a voxel detecting section that detects one voxel existing on a nearest side in a view direction of the medical image pickup apparatus among voxels included in the three-dimensional model;
a raised shape detecting section that acquires one curved surface including the one voxel to detect a position with gradient variation on the one curved surface and to determine whether or not body tissues with a locally raised shape exist in the position in the three-dimensional model; and
the raised shape detecting section traces the one curved surface along a plurality of trace lines set parallel to a predetermined axial direction, and then determines that the body tissues with a locally raised shape exist in one position when detecting that the number of trace lines with intensity gradient variation in the one position in the predetermined axial direction among the plurality of trace lines is equal to or larger than one and equal to or smaller than a predetermined threshold value.
"
US11701066,US17/094984,"Device and method for detecting clinically important objects in medical images with distance-based decision stratification","A method for performing a computer-aided diagnosis (CAD) includes: acquiring a medical image set; generating a three-dimensional (3D) tumor distance map corresponding to the medical image set, each voxel of the tumor distance map representing a distance from the voxel to a nearest boundary of a primary tumor present in the medical image set; and performing neural-network processing of the medical image set to generate a predicted probability map to predict presence and locations of oncology significant lymph nodes (OSLNs) in the medical image set, wherein voxels in the medical image set are stratified and processed according to the tumor distance map.","A method for performing a computer-aided diagnosis (CAD), comprising:
acquiring a medical image set;
generating a three-dimensional (3D) tumor distance map corresponding to the medical image set, each voxel of the tumor distance map representing a distance from the voxel to a nearest boundary of a primary tumor present in the medical image set; and
performing neural-network processing of the medical image set to generate a predicted probability map to predict presence and locations of oncology significant lymph nodes (OSLNs) in the medical image set, wherein voxels in the medical image set are stratified and processed according to the tumor distance map, wherein:
the medical image set includes a 3D non-contrast computer tomography (CT) image and a 3D positron emission tomography (PET) image registered to the CT image; and
performing neural-network processing of the medical image set includes:
dividing voxels in each of the CT image and the PET image into tumor-proximal voxels and tumor-distal voxels according to the tumor distance map and a distance threshold;
processing the CT image with a first sub-network trained on CT images with corresponding ground-truth maps to generate a first prediction map based on the tumor-proximal voxels and a second prediction map based on the tumor-distal voxels;
processing the CT image, the PET image, and the tumor distance map with a second sub-network jointly trained on CT images, PET images, tumor distance maps, and corresponding ground-truth maps to generate a third prediction map based on the tumor-proximal voxels and a fourth prediction map based on the tumor-distal voxels; and
performing a fusion operation on the first, second, third and fourth prediction maps to generate a fused prediction map.
"
US20110293157,US13/002490,"Medical image segmentation","A segmentation method comprises clustering spatial, intensity and volumetric shape index to automatically segment a medical lesion. The algorithm has the following steps: (1) calculating volumetric shape index (SI) for each voxel in the image; (2) combining the SI features with the intensity range and the spatial position (x, y, z) to form a 5-dimensional feature vector set; (3) grouping the 5-dimensional feature vector set into clusters; (4) employing a modified expectation-maximization algorithm (EM) considering not only spatial but also shape features on an intensity mode map from the clustering algorithm to merge the neighbouring regions or modes. The joint spatial-intensity-shape feature provides rich information for the segmentation of the anatomic structures of interest, such as lesions or tumours.","A method for segmenting a three-dimensional medical image, comprising:
receiving, by a computing device, medical image data representing spatial variation of the three-dimensional medical image;
deriving, by the computing device, shape data from the medical image data;
clustering, by the computing device, image data including the medical image data and the shape data, to generate a plurality of modes; and
outputting, by the computing device, segmentation data relating to the three-dimensional medical image, derived from the plurality of modes.
"
US20100104156,US12/652321,"Medical image processing apparatus and medical image processing method","The medical image processing apparatus of the present invention includes: a three-dimensional model estimating section that estimates a three-dimensional model based on a two-dimensional image; a local region setting section that sets a plurality of local regions around a target pixel in the two-dimensional image; a shape feature value calculating section that uses three-dimensional coordinate data corresponding to the plurality of local regions and calculates shape feature values of respective voxels corresponding to the target pixel; a shape feature value selecting section that selects, as a shape feature value of a voxel corresponding to the target pixel, a shape feature value calculated according to one local region including an optimum three-dimensional coordinate data amount among the plurality of shape feature values; and an elevated shape detecting section that detects an elevated shape existing in the two-dimensional image based on a selection result of the shape feature value selecting section.","A medical image processing apparatus, comprising:
a three-dimensional model estimating section that estimates a three-dimensional model of living tissue based on a two-dimensional image of an image of the living tissue inputted from a medical image pickup apparatus;
a local region setting section that sets a plurality of local regions around a target pixel in the two-dimensional image;
a shape feature value calculating section that uses three-dimensional coordinate data corresponding to each of the plurality of local regions and calculates shape feature values of respective voxels corresponding to the target pixel based on the three-dimensional model of the living tissue estimated by the three-dimensional model estimating section;
a shape feature value selecting section that selects, as an optimum shape feature value of a voxel corresponding to the target pixel, a shape feature value calculated according to one local region including an optimum three-dimensional coordinate data amount among the plurality of shape feature values calculated according to the plurality of local regions; and
an elevated shape detecting section that detects an elevated shape existing in the two-dimensional image based on a selection result of the shape feature value selecting section.
"
US20090220133,US12/388832,"Medical image processing apparatus and medical image processing method","A medical image processing apparatus of the present invention includes: a three-dimensional model estimating section for estimating a three-dimensional model of an object based on a two-dimensional image of an image of the object which is inputted from a medical image pickup apparatus; an image dividing section for dividing the two-dimensional image into a plurality of regions each of which includes at least one or more pixels; a feature value calculation section for calculating a feature value according to a grayscale of each pixel in one region for each of the plurality of regions; and a lesion detection reference setting section for setting lesion detection reference for detecting a locally protruding lesion in the regions of the three-dimensional model which correspond to each of the plurality of regions, based on the feature value according to the grayscale.","A medical image processing apparatus, comprising:
a three-dimensional model estimating section for estimating a three-dimensional model of an object based on a two-dimensional image of an image of the object which is inputted from a medical image pickup apparatus;
an image dividing section for dividing the two-dimensional image into a plurality of regions each of which includes at least one or more pixels;
a feature value calculation section for calculating a feature value according to a grayscale of each pixel in one region for each of the plurality of regions; and
a lesion detection reference setting section for setting a lesion detection reference for detecting a locally protruding lesion in the regions of the three-dimensional model which correspond to each of the plurality of regions, based on the feature value according to the grayscale.
"
US20110081055,US12/572614,"Medical image analysis system using n-way belief propagation for anatomical images subject to deformation and related methods","A medical image analysis system is for first and second anatomical image data of a same body area and subject to deformation, with the first and second anatomical image data including respective first and second sets of voxels. The medical image analysis system may include a processor cooperating with a memory and configured to generate a plurality of cost arrays, with each cost array based upon probabilities of a subset of voxels of the second anatomical image data matching voxels of the first anatomical image data. The processor may also solve each cost array using three-dimensional, N-way belief propagation to thereby generate a deformation vector array between the first and second anatomical image data, where N is an integer greater than or equal to six.","A medical image analysis system for first and second anatomical image data of a same body area and subject to deformation, the first and second anatomical image data comprising respective first and second sets of voxels, the medical image analysis system comprising:
a memory; and
a processor cooperating with said memory and configured to
generate a plurality of cost arrays, each cost array based upon probabilities of a subset of voxels of the second anatomical image data matching voxels of the first anatomical image data, and
solve each cost array using three-dimensional, N-way belief propagation to thereby generate a deformation vector array between the first and second anatomical image data, where N is an integer greater than or equal to six.
"
US20130060540,US13/578758,"Systems and methods that generate height map models for efficient three dimensional reconstruction from depth information","Methods of generating a three dimensional representation of an object in a reference plane from a depth map including distances from a reference point to pixels in an image of the object taken from a reference point. Weights are assigned to respective voxels in a three dimensional grid along rays extending from the reference point through the pixels in the image based on the distances in the depth map from the reference point to the respective pixels, and a height map including an array of height values in the reference plane is formed based on the assigned weights. An n-layer height map may be constructed by generating a probabilistic occupancy grid for the voxels and forming an n-dimensional height map comprising an array of layer height values in the reference plane based on the probabilistic occupancy grid.","A method of generating a three dimensional representation of an object in a reference plane, comprising:
providing a two dimensional grid of cells that define the reference plane in which at least a portion of the object is located;
providing a three dimensional grid of voxels that define a physical volume above the two-dimensional grid of cells;
providing a depth map in a processing unit, the depth map comprising distances from a reference point to pixels in an image of the object taken from the reference point, wherein the pixels in the image correspond to features of the object visible in the image;
assigning weights in the processing unit to respective ones of the voxels in the three dimensional grid along rays extending from the reference point through the pixels in the image based on the distances in the depth map from the reference point to the respective pixels; and
forming a height map in the processing unit, the height map comprising an array of height values in the reference plane based on the assigned weights.
"
US6205350,US09/251681,"Medical diagnostic method for the two-dimensional imaging of structures","The invention relates to a medical diagnostic method in which a two-dimensional image can be derived from a data set representing a three-dimensional examination zone while especially emphasizing given structures. The data set is subjected to a filtering operation and from the voxels which are projected onto the same pixel in the two-dimensional image a voxel is selected in dependence on its image value in the second data set. This voxel is reproduced with its original image value in the two-dimensional image.","A medical diagnostic method for the two-dimensional imaging of structures present in an object comprising:
acquiring a first data set (I(x,y,z)) from the object in order to define voxel image values for the voxels within a three-dimensional examination zone, 
generating a second data set (F(x,y,z)) from the first data set by a filtering operation which emphasizes the structures, 
determining voxels (x,y,z) which are projected onto the same pixel (u,v) in a two-dimensional image, 
selecting of at least one of these voxels (x,y,z) in dependence on its voxel image value (F(x,y,z)) in the second data set, and 
generating the two-dimensional image (B1(u,v)), the image value for the pixel (u,v) being derived from the voxel image value (I(x,y,z)) of the selected voxel in the first data set. 
"
US20120189178,US13/358029,"Method and apparatus for automatically generating optimal 2-dimensional medical image from 3-dimensional medical image","In a method and an apparatus for automatically generating an optimal 2-dimensional (2D) medical image from a 3D medical image, at least one virtual plane crossing a 3D volume is generated from 3D volume image data for showing part of a patient's body in a 3D manner, at least one 2D image representing a cross section of the part of the patient's body is generated by applying the 3D volume image data to the virtual plane, and a 2D image suitable for diagnosis of the patient having a feature most similar to a target feature from among the at least one 2D image is output.","A method of generating a 2-dimensional (2D) image, the method comprising:
receiving 3-dimensional (3D) volume image data for showing a part of a patient's body in a 3D manner;
generating at least one virtual plane crossing the 3D volume;
generating at least one 2D image representing a cross section of the part of the patient's body by applying the 3D volume image data to the at least one virtual plane; and
outputting a 2D image having a feature most similar to a target feature from among the at least one 2D image.
"
US20220284570,US17/192804,"System and methods for inferring thickness of anatomical classes of interest in two-dimensional medical images using deep neural networks","Methods and systems are provided for inferring thickness and volume of one or more object classes of interest in two-dimensional (2D) medical images, using deep neural networks. In an exemplary embodiment, a thickness of an object class of interest may be inferred by acquiring a 2D medical image, extracting features from the 2D medical image, mapping the features to a segmentation mask for an object class of interest using a first convolutional neural network (CNN), mapping the features to a thickness mask for the object class of interest using a second CNN, wherein the thickness mask indicates a thickness of the object class of interest at each pixel of a plurality of pixels of the 2D medical image; and determining a volume of the object class of interest based on the thickness mask and the segmentation mask.","A method comprising:
receiving a two-dimensional (2D) medical image;
extracting features from the 2D medical image;
mapping the features to a segmentation mask for an object class of interest using a first convolutional neural network (CNN);
mapping the features to a thickness mask for the object class of interest using a second CNN, wherein the thickness mask indicates a thickness of the object class of interest at each pixel of a plurality of pixels of the 2D medical image; and
determining a volume of the object class of interest based on the thickness mask and the segmentation mask.
"
US10398395,US15/098756,"Medical image diagnostic apparatus","A medical image diagnostic apparatus includes storage circuitry and processing circuitry. The storage circuitry is configured to store three-dimensional medical image data that is obtained by imaging a subject. The processing circuitry is configured to set a region of attention in each of medical images of the three-dimensional medical image data corresponding to at least two directions. The processing circuitry is configured to calculate, based on the regions of attention, a region of interest in the three-dimensional medical image data on the subject. The processing circuitry is configured to calculate, based on voxel values of the region of interest, a parameter value relating to image processing on a medical image that is generated from the three-dimensional medical image data. The processing circuitry is configured to generate a display image by performing rendering processing on the basis of the three-dimensional medical image data and the parameter value.","A medical image diagnostic apparatus comprising:
storage circuitry configured to store three-dimensional medical image data that is obtained by imaging a subject; and
processing circuitry configured to
set a first region of attention in a first medical image in which the subject is shown from a first direction in the three-dimensional medical image data and a second region of attention in a second medical image in which the subject is shown from a second direction different from the first direction in the three-dimensional medical image data, based on operations accepted from an operator or the operator's line of sight with respect to the first medical image and the second medical image,
calculate a first depth region that is three-dimensional region obtained by extending the first region of attention in the depth direction on the three-dimensional medical image data and a second depth region that is three-dimensional region obtained by extending the second region of attention in the depth direction on the three-dimensional medical image data,
calculate, as the region of interest, a group of voxels contained in both the first depth region and the second depth region,
determine, based on voxel values of the region of interest, a candidate for parameter value relating to image processing on a medical image to be generated from the three-dimensional medical image data, and
cause a display to display the candidate for parameter value.
"
US6278460,US09/211899,"Creating a three-dimensional model from two-dimensional images","A method is provided in which three-dimensional models are created from a number of two-dimensional images, e.g., a video stream of two-dimensional images or still images, using a single camera without prior knowledge of the position or orientation of the camera, its focal length, etc. The method derives a relative value related to the position or orientation of the camera for each two-dimensional image and then, based on the derived position or orientation, uses ""ray casting"" to develop the three-dimensional model based on intersecting rays through common features of sequential two-dimensional images.","A method for creating a three-dimensional model of an object, the method comprising:
receiving a number of two-dimensional images of the object; 
tracking the location of a plurality of features through the two-dimensional images; 
storing the locations for the plurality of features; 
deriving a value related to a camera position or orientation for each of the two-dimensional images from the stored locations for the plurality of features; and 
for each of the plurality of features, processing a plurality of pairs of two-dimensional images to create a point cloud model, the processing including: 
casting a ray through each pixel in the feature in each of first and second two-dimensional images of a pair of two-dimensional images based on the value relative to the camera position or orientation and the pixel location in each of the first and second two-dimensional images, 
determining the intersections of the rays of the first two-dimensional image with the rays of the second two-dimensional image, 
creating a voxel for a three-dimensional point cloud model at each intersection, and 
converting the point cloud to a polygon-based format. 
"
US7224357,US09/848773,"Three-dimensional modeling based on photographic images","A system of determining three-dimensional information from the information that is contained into discrete two-dimensional images. The two images may be obtained from two uncalibrated cameras. The information from the two uncalibrated cameras is first rectified, and then used to form a disparity surface indicating the third dimensional information. Various techniques are used to increase the speed of conversion.","A method, comprising:
obtaining two images of similar image information from two uncalibrated sources;
superimposing lines formed on said images to rectify the two images relative to one another to form rectified images;
using said rectified images to form three-dimensional information by forming a disparity map of three dimensional information for specified coordinates of matching pixels;
wherein said using comprises forming a three-dimensional surface indicative of three-dimensional information contained in said two images, and forming a variable which indicates a likelihood of error in said three-dimensional surface; and
wherein said forming a variable comprises forming a plurality of seed voxels which have a probability of being correct greater than a specificed amount which makes it unlikely that the voxels will not be correct, and tracing a surface from said plurality of seed voxels.
"
US20060044310,US11/170421,"Candidate generation for lung nodule detection","A computer-implemented method for candidate generation in three-dimensional volumetric data comprises forming a binary volumetric image of the three-dimensional volumetric data including labeled foreground voxels, estimating a plurality of shape features of the labeled foreground voxels in the binary volumetric data including, identifying peak voxels and high curvature voxels from the foreground voxels in the binary volumetric image, accumulating a plurality of confidence values for boundary and each peak voxel, and detecting confidence peaks from the plurality of confidence values, wherein the confidence peaks are determined to be the candidate points, and refining the candidate points given detected confidence peaks, wherein refined candidate points are determined to be candidates.","A computer-implemented method for candidate generation in three-dimensional volumetric data comprising: 
forming a binary volumetric image of the three-dimensional volumetric data including labeled foreground voxels; 
estimating a plurality of shape features of the labeled foreground voxels in the binary volumetric data comprising, 
identifying peak voxels and high curvature voxels from the foreground voxels in the binary volumetric image, 
accumulating a plurality of confidence values for each boundary voxel and each peak voxel, 
detecting confidence peaks from the plurality of confidence values, wherein the confidence peaks are determined to be the candidate points; and 
refining the candidate points given detected confidence peaks, wherein refined candidate points are determined to be candidates. 
"
US7471815,US11/170421,"Candidate generation for lung nodule detection","A computer-implemented method for candidate generation in three-dimensional volumetric data comprises forming a binary volumetric image of the three-dimensional volumetric data including labeled foreground voxels, estimating a plurality of shape features of the labeled foreground voxels in the binary volumetric data including, identifying peak voxels and high curvature voxels from the foreground voxels in the binary volumetric image, accumulating a plurality of confidence values for boundary and each peak voxel, and detecting confidence peaks from the plurality of confidence values, wherein the confidence peaks are determined to be the candidate points, and refining the candidate points given detected confidence peaks, wherein refined candidate points are determined to be candidates.","A computer-implemented method for candidate generation in three-dimensional volumetric data comprising:
performing, using a computer processor, the steps of:
forming a binary volumetric image of the three-dimensional volumetric data including labeled foreground voxels, where the foreground voxels comprising a plurality of pixels of the binary volumetric image; estimating a plurality of shape features of the labeled foreground voxels in a plurality of cross-sections of the binary volumetric data comprising: identifying high curvature voxels from the foreground voxels in the plurality of cross-sections as voxels having a curvature greater than a threshold curvature and identifying peak voxels among the voxels having the curvature greater than the threshold, wherein the peak voxels have a curvature value reaching a maximum with a local neighborhood of a predefined size, accumulating a confidence value for each peak voxel, wherein a confidence value for each peak voxel increases with a number of voxels having the curvature greater than the threshold in a patch grown around the peak voxel, detecting confidence peaks from the plurality of confidence values, wherein the confidence peaks are determined to be the candidate points; and refining the candidate points given detected confidence peaks, wherein refined candidate points constitute a candidate object in the three-dimensional volumetric data.
"
US20210383552,US17/310330,"Layer boundary evolution for macular optical coherence tomography segmentation","A device receives a two-dimensional (2-D) image that depicts a cross-sectional view of a retina that includes a macula comprised of layers and boundaries used to segment the layers. The device converts the 2-D image to a standardized format, determines features for voxels included in the 2-D image, and generates, by using a data model to process the features, probability maps that indicate likelihoods of the voxels being in positions within particular boundaries. The device analyzes the probability maps to determine an initial set of boundary positions and to generate directional vectors that point in directions based on values included in the set of probability maps, determines a final set of boundary positions by performing a layer boundary evolution technique using the directional vectors to refine the initial set of boundary positions, and provides data that identifies the final set of boundary positions for display via an interface.","A method, comprising:
receiving, by a device, a two-dimensional (2-D) image that depicts a cross-sectional view of a retina of an eye,
wherein the retina includes a macula that includes:
layers, and
boundaries that are used to segment the layers;
converting, by the device, the 2-D image to a standardized format;
determining, by the device, a set of features for voxels included in the 2-D image;
generating, by the device and by using a data model to process the set of features, a set of probability maps that indicate likelihoods of the voxels being in positions within particular boundaries,
wherein the data model has been trained by using one or more machine learning techniques to analyze a labeled set of 2-D images that depict retinas of eyes;
determining, by the device and by analyzing the set of probability maps, an initial set of boundary positions for the boundaries;
generating, by the device and by analyzing the set of probability maps, a set of directional vectors that point in directions that are based on values included in the set of probability maps;
determining, by the device and by performing a layer boundary evolution (LBE) technique, a final set of boundary positions for the boundaries,
wherein performing the LBE technique includes using the set of directional vectors to refine the initial set of boundary positions; and
providing, by the device, data that identifies the final set of boundary positions for display via an interface.
"
US10339411,US14/868205,"System to represent three-dimensional objects","A three-dimensional (3D) object may be represented by object data. The object data includes probability distributions that describe particular features on the 3D object. A probability distribution represents the value of local descriptors for the same feature as obtained from a plurality of images at different camera poses relative to the 3D object. A query image may be processed to determine features, and the query local descriptors of those features may be used to test against previously stored probability distributions. A combination of probability distributions that show a high probability of corresponding to the query local descriptors may be used to identify the 3D object appearing in the query image.","A computer-implemented method comprising:
accessing a query image;
determining a query feature of the query image using a scale-invariant feature transform (SIFT) algorithm;
determining a query local descriptor value produced by the SIFT algorithm with respect to the query feature;
accessing object data comprising:
an object identifier indicative of a three-dimensional (3D) object,
a feature identifier indicative of a feature on the 3D object,
a distribution identifier indicative of a type of probability distribution descriptive of a plurality of local descriptor values of the feature, each of the plurality of local descriptor values indicative of the feature as viewed from a particular camera pose,
a distribution parameter associated with the distribution identifier, wherein the distribution parameter is indicative of a constant value used to define one or more characteristics of the type of probability distribution;
determining, using the type of probability distribution and the distribution parameter, a probability that the query local descriptor value is represented by the object data;
determining the probability of the query local descriptor value exceeds a threshold value; and
generating data indicative of a match between the query feature and the feature on the 3D object.
"
US20240221162,US18/610181,"Three dimensional object segmentation of medical images localized with object detection","The present disclosure relates to techniques for segmenting objects within medical images using a deep learning network that is localized with object detection based on a derived contrast mechanism. Particularly, aspects are directed to localizing an object of interest within a first medical image having a first characteristic, projecting a bounding box or segmentation mask of the object of interest onto a second medical image having a second characteristic to define a portion of the second medical image, and inputting the portion of the second medical image into a deep learning model that is constructed as a detector using a weighted loss function capable of segmenting the portion of the second medical image and generating a segmentation boundary around the object of interest. The segmentation boundary may be used to calculate a volume of the object of interest for determining a diagnosis and/or a prognosis of a subject.","A method for segmenting objects within medical images, comprising:
obtaining medical images of a subject, the medical images include a first image having a first characteristic and a second image having a second characteristic, wherein the first characteristic includes a first contrast that facilitates detection of an object of interest, and the second characteristic includes a second contrast that facilitates segmenting the object of interest;
determining, using a localization model, a bounding box or a segmentation mask for the object of interest within the first image based on sets of pixels or voxels assigned with an object class of a plurality of object classes, wherein the localization model classifies the sets of pixels or voxels by assigning the sets of pixels or voxels of the first image using one or more clustering algorithms based on values of the first contrast;
projecting the bounding box or the segmentation mask onto the second image to define a portion of the second image comprising the object of interest;
inputting the portion of the second image into a three-dimensional neural network model constructed for volumetric segmentation;
generating, using the three-dimensional neural network model, an estimated segmentation boundary around the object of interest, wherein the three-dimensional neural network model estimates the segmentation boundary by extracting features from the second image based on values of the second contrast; and
outputting, using the three-dimensional neural network model, the portion of the second image with the estimated segmentation boundary around the object of interest.
"
US12354264,US18/610181,"Three dimensional object segmentation of medical images localized with object detection","The present disclosure relates to techniques for segmenting objects within medical images using a deep learning network that is localized with object detection based on a derived contrast mechanism. Particularly, aspects are directed to localizing an object of interest within a first medical image having a first characteristic, projecting a bounding box or segmentation mask of the object of interest onto a second medical image having a second characteristic to define a portion of the second medical image, and inputting the portion of the second medical image into a deep learning model that is constructed as a detector using a weighted loss function capable of segmenting the portion of the second medical image and generating a segmentation boundary around the object of interest. The segmentation boundary may be used to calculate a volume of the object of interest for determining a diagnosis and/or a prognosis of a subject.","A method for segmenting objects within medical images, comprising:
obtaining medical images of a subject, the medical images include a first image having a first characteristic and a second image having a second characteristic, wherein the first characteristic includes a first contrast that facilitates detection of an object of interest, and the second characteristic includes a second contrast that facilitates segmenting the object of interest;
determining, using a localization model, a bounding box or a segmentation mask for the object of interest within the first image based on sets of pixels or voxels assigned with an object class of a plurality of object classes, wherein the localization model classifies the sets of pixels or voxels by assigning the sets of pixels or voxels of the first image using one or more clustering algorithms based on values of the first contrast;
projecting the bounding box or the segmentation mask onto the second image to define a portion of the second image comprising the object of interest;
inputting the portion of the second image into a three-dimensional neural network model constructed for volumetric segmentation;
generating, using the three-dimensional neural network model, an estimated segmentation boundary around the object of interest, wherein the three-dimensional neural network model estimates the segmentation boundary by extracting features from the second image based on values of the second contrast; and
outputting, using the three-dimensional neural network model, the portion of the second image with the estimated segmentation boundary around the object of interest.
"
US7924279,US10/539387,"Protocol-based volume visualization","A system for visualizing a 3D volume, in particular for medical applications, includes an input 1010 for receiving a three-dimensional set of data representing voxel values of the 3D volume. The data set is stored in a storage 1030. A processor projects the volume onto an imaginary 2D projection screen from a predetermined viewpoint. For each pixel of the 2D projection image a ray is cast through the pixel and through the volume. A protocol is used that, while traversing along ray positions within the volume, determines a rendering algorithm and/or rendering parameters in dependence on the ray position. For each ray position the determined rendering algorithm/parameters are used to calculate a contribution to a pixel value of the pixel based on at least one voxel value within a predetermined range of the ray position. An output 1040 is used for providing pixel values of a 2D image for rendering on a display.","A system for visualizing a three-dimensional (hereinafter “3D”) volume, in particular for medical applications; the system including:
an input for receiving a three-dimensional set of data representing voxel values of the 3D image;
a storage for storing the data set;
an output for providing pixel values of a two-dimensional (hereinafter “2D”) image for rendering; and
a processor for, under control of a computer program, processing the data set to obtain a 2-dimensional representation of the volume by projecting the volume onto an imaginary 2D projection screen from a predetermined viewpoint by for each pixel of the 2D projection image:
casting a ray from the viewpoint through the pixel and through the volume;
traversing along the ray through at least a plurality of ray positions within the volume under control of a protocol that determines a rendering algorithm and/or rendering parameters in dependence on the ray position with the determined rendering algorithms and/or rendering parameters being different for some ray positions than the determined rendering algorithm and/or rendering parameters for other ray positions; and
for each of the plurality of ray positions using a corresponding one of the determined rendering algorithms/parameters to calculate a contribution to a pixel value of the pixel based on at least one voxel value with a predetermined range of ray positions,
wherein the protocol is rule-based;
wherein a rule prescribes for each of the plurality of ray positions at least one processing action at least in dependence on processing results of ray position along the ray that already been processed wherein the processing action includes at least one of the following:
jumping forward or backward along a ray to a particular ray position, and resuming processing from that position;
switching a stepping direction along a ray between forward and backward as seen from the viewpoint;
changing a step size that determines a next ray position with respect to a current ray position in the stepping direction;
changing a 3-dimensional direction of a ray starting from a particular position;
switching to another rendering algorithm;
adapting rendering parameters for controlling the rendering algorithm;
switching to another feature detection method, which determines the type of information that is going to be visualized by the rendering algorithm.
"
US20200364863,US16/985966,"Object recognition method and device, and storage medium","An object recognition method is performed at an electronic device. The method includes: pre-processing a target image, to obtain a pre-processed image, the pre-processed image including three-dimensional image information of a target region of a to-be-detected object, processing the pre-processed image by using a target data model, to obtain a target probability, the target probability being used for representing a probability that an abnormality appears in a target object in the target region of the to-be-detected object; and determining a recognition result of the target region of the to-be-detected object according to the target probability, the recognition result being used for indicating the probability that the abnormality appears in the target region of the to-be-detected object. The object recognition method can effectively improve accuracy of object recognition and avoid a case of incorrect recognition.","An object recognition method, applied to an electronic device having a processor and memory storing a plurality of operations to be executed by the processor, the method comprising:
pre-processing a target image, to obtain a pre-processed image, the pre-processed image comprising three-dimensional image information of a target region of a to-be-detected object;
processing the pre-processed image by using a target data model, to obtain a target probability, the target probability being used for representing a probability that an abnormality appears in a target object in the target region of the to-be-detected object, and the target data model being obtained by training a convolutional neural network by using a plurality of sets of data; each of the plurality of sets of data comprising three-dimensional image information of a target region of a sample object and indication information corresponding to the three-dimensional image information, the indication information being used for indicating whether an abnormality appears in the target object in the target region of the sample object, and the three-dimensional image information of the target region of the sample object being at least used for representing the target object in the target region of the sample object; and
determining a recognition result of the target region of the to-be-detected object according to the target probability, the recognition result being used for indicating a probability that an abnormality appears in the target region of the to-be-detected object.
"
US20200256999,US16/783975,"Lidar techniques for autonomous vehicles","A Laser Imaging Detection and Ranging (LIDAR) system comprises a memory configured to store LIDAR measurement data obtained by the LIDAR system representative of a three-dimensional (3D) space in a field of view of the LIDAR system and signal processing circuitry. The signal processing circuitry is and configured to convert the LIDAR measurement data to a voxel characteristic of voxels of the 3D space, process and adjust a voxel characteristic of a first voxel of the 3D space using a voxel characteristic of other voxels within a specified distance of the first voxel in the 3D space, continue to process and adjust the voxel characteristics of all voxels in the 3D space, and generate an indication of presence of an object in the field of view according to the adjusted voxel characteristics.","A Laser Imaging Detection and Ranging (LIDAR) system, the system comprising:
a memory configured to store LIDAR measurement data obtained by the LIDAR system representative of a three-dimensional (3D) space in a field of view of the LIDAR system; and
signal processing circuitry operatively coupled to the memory and configured to:
convert the LIDAR measurement data to a voxel characteristic of voxels of the 3D space;
process and adjust a voxel characteristic of a first voxel of the 3D space using a voxel characteristic of other voxels within a specified distance of the first voxel in the 3D space;
continue to process and adjust the voxel characteristics of all voxels in the 3D space; and
generate an indication of presence of an object in the field of view according to the adjusted voxel characteristics.
"
US20170109925,US14/984340,"Utilizing depth from ultrasound volume rendering for 3d printing","Systems and methods are provided for utilizing depth from volume rendering for 3D printing. Three-dimensional (3D) mesh data may be generated based on one or more volume rendered images and/or volumetric datasets corresponding thereto, obtained during medical imaging (e.g., based on echo ultrasound signals during ultrasound imaging). Generating the 3D mesh data may comprise computing a plurality of depth values, where each depth value corresponds to a particular voxel in the volumetric medical imaging datasets. The 3D mesh data may be configured to enable producing a physical volume representation of one or more objects and/or structures in the one or more volume rendered images. Thus, the 3D mesh data may be used for 3D printing. For example, 3D printing data may be generated based on the 3D mesh data. The 3D printing data may be configured and formatted based on a pre-defined 3D printing standard or file format.","A system, comprising:
an electronic device comprising at least one processor, the electronic device is operable to:
generate, based on at least one of one or more volume rendered images and volumetric medical imaging datasets corresponding to the one or more volume rendered images, three-dimensional (3D) mesh data;
wherein:
the 3D mesh data is configured to enable producing a physical volume representation of at least one of one or more objects and structures in the one or more volume rendered images; and
generating the 3D mesh data comprises computing a plurality of depth values, where each depth value corresponds to a particular voxel in the volumetric medical imaging datasets.
"
US7352882,US10/916808,"System and method for determining compactness in images","An image processing system for recognizing image features in three dimensional images, which can be medical images, uses a mask generator for generating masks that are used by a candidate searcher to search for candidate images in the three dimensional image. The candidate searcher applies the mask to a section of a foreground region of the image to determine the presence of a structure/object by counting the number of intersections between the mask and the section of the foreground region.","An image processing system for recognizing objects in three dimensional images, the system comprising:
a mask generator for generating at least one mask, wherein the mask comprises a three dimensional image including a plurality of voxels and having a plurality of faces, wherein at least one of the voxels has a masking value; and
a candidate searcher for searching at least one candidate object similar to at least one predetermined object in at least one three dimensional image, the candidate searcher applying the mask to a predetermined region of a foreground image section of the three dimensional image by overlaying the mask on the predetermined region to determine an intersection count between the mask voxels and the predetermined region to search for the candidates.
"
US20200410751,US16/457653,"Dynamic object detection model based on static map collection data","Systems, methods, and non-transitory computer-readable media can obtain information describing a static map of a geographic location, wherein the static map is determined based at least in part on a plurality of three-dimensional representations of the geographic location captured by one or more sensors of one or more vehicles. At least one training example that includes visual features and a corresponding label can be generated based on an unsupervised process for generating training examples, wherein the visual features are extracted based on the static map and at least one three-dimensional representation of the geographic location. At least one machine learning model can be trained to distinguish between static objects and non-static objects in visual data based on the at least one training example, wherein the at least one machine learning model is trained based on an unsupervised learning process.","A computer-implemented method comprising:
obtaining, by a computing system, information describing a static map of a geographic location, wherein the static map is determined based at least in part on a plurality of three-dimensional representations of the geographic location captured by one or more sensors of one or more of vehicles;
generating, by the computing system, at least one training example that includes visual features and a corresponding label based on an unsupervised process for generating training examples, wherein the visual features are extracted based on the static map and at least one three-dimensional representation of the geographic location; and
training, by the computing system, at least one machine learning model to distinguish between static objects and non-static objects in visual data based on the at least one training example, wherein the at least one machine learning model is trained based on an unsupervised learning process.
"
US11170567,US16/457653,"Dynamic object detection model based on static map collection data","Systems, methods, and non-transitory computer-readable media can obtain information describing a static map of a geographic location, wherein the static map is determined based at least in part on a plurality of three-dimensional representations of the geographic location captured by one or more sensors of one or more vehicles. At least one training example that includes visual features and a corresponding label can be generated based on an unsupervised process for generating training examples, wherein the visual features are extracted based on the static map and at least one three-dimensional representation of the geographic location. At least one machine learning model can be trained to distinguish between static objects and non-static objects in visual data based on the at least one training example, wherein the at least one machine learning model is trained based on an unsupervised learning process.","A computer-implemented method comprising:
obtaining, by a computing system, information describing a static map of a geographic location, wherein the static map is determined based at least in part on at least one three-dimensional representation of the geographic location captured by one or more sensors of one or more vehicles;
generating, by the computing system, at least one training example that includes visual features and a corresponding label based on an unsupervised process for generating training examples, wherein the visual features are extracted based on the static map and the at least one three-dimensional representation of the geographic location, and wherein generating the at least one training example comprises:
determining, by the computing system, one or more contiguous voxels associated with the static map based on respective probabilities associated with the one or more contiguous voxels, wherein each voxel of the one or more contiguous voxels is associated with a probability that indicates whether a static object or a dynamic object is represented within the voxel;
training, by the computing system, at least one machine learning model to distinguish between static objects and dynamic objects in visual data based on the at least one training example, wherein the at least one machine learning model is trained based on an unsupervised learning process; and
applying, by the computing system, the at least one machine learning model to determine whether an object is a static object or a dynamic object.
"
US20230310896,US17/710975,"Determining uncertainty in  radiation therapy delivered dose  accumulation","A computer-implemented method of generating dose information for a region of patient anatomy includes determining a first set of dose values for a first three-dimensional (3D) image of the region, wherein each value in the first set of dose values is associated with a different voxel of the first 3D image, and wherein the first 3D image is associated with a specific application of dose to the region; determining a second set of dose values for a representative 3D image of the region, wherein each value in the second set of dose values is associated with a different voxel of the representative 3D image; determining a set of geometric error models for the representative 3D image of the region, wherein each geometric error model in the set of geometric error models indicates a geometric error between a voxel of the representative 3D image and one or more voxels of a treatment fraction 3D image of the region; and based on the second set of dose values and the set of geometric error models, determining a set of dose probability values for each voxel of the representative 3D image, wherein each set of dose probability values includes at least one dose value and a probability value that corresponds to the dose value.","A computer-implemented method of generating dose information for a region of patient anatomy, the method comprising:
determining a first set of dose values for a first three-dimensional (3D) image of the region, wherein each value in the first set of dose values is associated with a different voxel of the first 3D image, and wherein the first 3D image is associated with a specific application of dose to the region;
determining a second set of dose values for a representative 3D image of the region, wherein each value in the second set of dose values is associated with a different voxel of the representative 3D image;
determining a set of geometric error models for the representative 3D image of the region, wherein each geometric error model in the set of geometric error models indicates a geometric error between a voxel of the representative 3D image and one or more voxels of a treatment fraction 3D image of the region; and
based on the second set of dose values and the set of geometric error models, determining a set of dose probability values for each voxel of the representative 3D image, wherein each set of dose probability values includes at least one dose value and a probability value that corresponds to the dose value.
"
US12318633,US17/710975,"Determining uncertainty in radiation therapy delivered dose accumulation","A computer-implemented method of generating dose information for a region of patient anatomy includes determining a first set of dose values for a first three-dimensional (3D) image of the region, wherein each value in the first set of dose values is associated with a different voxel of the first 3D image, and wherein the first 3D image is associated with a specific application of dose to the region; determining a second set of dose values for a representative 3D image of the region, wherein each value in the second set of dose values is associated with a different voxel of the representative 3D image; determining a set of geometric error models for the representative 3D image of the region, wherein each geometric error model in the set of geometric error models indicates a geometric error between a voxel of the representative 3D image and one or more voxels of a treatment fraction 3D image of the region; and based on the second set of dose values and the set of geometric error models, determining a set of dose probability values for each voxel of the representative 3D image, wherein each set of dose probability values includes at least one dose value and a probability value that corresponds to the dose value.","A computer-implemented method of generating dose information for a region of patient anatomy, the method comprising:
determining a first set of dose values for a day-of-treatment three-dimensional (3D) image of the region, wherein each value in the first set of dose values is associated with a different voxel of the first 3D image, and wherein the day-of-treatment 3D image is associated with a specific application of dose to the region for a treatment fraction;
determining a second set of dose values for a representative 3D image of the region, wherein the representative 3D image corresponds to a treatment planning image of the region obtained prior to the day-of-treatment 3D image, and each value in the second set of dose values is associated with a different voxel of the representative 3D image;
determining a set of geometric error models for the representative 3D image of the region, wherein each geometric error model in the set of geometric error models indicates a geometric error between a voxel of the representative 3D image and one or more voxels of the day-of-treatment 3D image of the region for the treatment fraction;
based on the second set of dose values and the set of geometric error models, determining a set of dose probability values for each voxel of the representative 3D image, wherein each set of dose probability values includes at least one dose value and a probability value that a voxel of the representative 3D image corresponds to the dose value; and
presenting a delivered dose distribution for a portion of the representative 3D image and uncertainty information associated with the delivered dose distribution to a clinician, wherein the uncertainty information is based on the sets of dose probability values.
"
US20200364856,US16/767785,"Three-dimensional medical image analysis method and system for identification of vertebral fractures","A machine-based learning method estimates a probability of bone fractures in a 3D image, more specifically vertebral fractures. The method and system utilizing such method utilize a data-driven computational model to learn 3D image features for classifying vertebra fractures. A three-dimensional medical image analysis system for predicting a presence of a vertebral fracture in a subject includes a 3D image processor for receiving and processing 3D image data of a 3D image of the subject, producing two or more sets of 3D voxels. Each of the sets of 3D voxels corresponds to an entirety of the 3D image and each of the sets of 3D voxels consists of equal 3D voxels of different dimensions. The system also includes a voxel classifier for assigning the 3D voxels one or more class probabilities each of the 3D voxels contains a fracture using a computational model, and a fracture probability estimator for estimating a probability of the presence of a vertebral fracture in the subject.","A three-dimensional medical image analysis system for predicting a presence of a vertebral fracture in a subject, comprising:
a 3D image processor for receiving and processing 3D image data of a 3D image of the subject, producing two or more sets of 3D voxels, each of the sets of 3D voxels corresponding to an entirety of the 3D image, each of the sets of 3D voxels consisting of equal 3D voxels of different dimensions;
a voxel classifier for assigning the 3D voxels one or more class probabilities each of the 3D voxels contains a fracture using a computational model; and
a fracture probability estimator for estimating a probability of the presence of a vertebral fracture in the subject.
"
US20080080757,US11/905255,"Method for vessel enhancement and segmentation in 3-d volume data","A method is disclosed for the segmented representation of vessel-like structures of an object under examination, on the basis of tomographic data, wherein a three-dimensional tomographic volume data record of the object under examination is generated and a segmentation is carried out which enhances the vessel-like structures in the representation of the tomographic data. According to an embodiment of the invention, for each voxel, the probability with which the voxel is located in a vessel structure is determined from the environmental data of the voxel with the aid of a vessel-specific filter of a spatial dimension which corresponds to the tomographic volume data record, on the basis of Gaussian functions, and these determined probabilities are additionally used as criterion for the presence of a vessel in the segmentation process for the representation of vessel structures. An embodiment of the invention also relates to a tomography system, with a device for scanning an object under examination, preferably a patient, and at least one computer system for editing tomographic image data records containing a memory for storing program code and a processor system for executing the programs, wherein program code is stored which executes the method steps of an embodiment of the method.","A method for the segmented representation of vessel-like structures of an object under examination on the basis of tomographic data, comprising:
generating a three-dimensional tomographic volume data record of an object under examination having vessel-like internal structures;
carrying out, using the generated tomographic volume data record, a segmentation which enhances the vessel-like structures in the representation of the tomographic data;
determining, for each voxel of the tomographic volume data record, the probability with which the voxel is located in a vessel structure from the environmental data of the voxel with the aid of a vessel-specific filter of a spatial dimension which corresponds to the tomographic volume data record, on the basis of Gaussian functions; and
using the determined probabilities as criterion for the presence of a vessel in the segmentation process for the representation of vessel structures.
"
US11836852,US17/124637,"Neural network-based millimeter-wave imaging system","A method includes receiving data including a plurality of data items, each data item of the plurality of data items including a three-dimensional (3D) radar heat map of an object and a corresponding two-dimensional (2D) image of the object captured by a stereo camera, inputting the training dataset into a machine learning model including a neural network (NN) that generates, from the 3D radar heat map, a 2D depth map for the object and outputs a probability that the 2D depth map is the corresponding 2D image of the object, and training the machine learning model based on a training dataset to generate a trained machine learning model that iteratively learns to generate an updated 2D depth map that approximates the corresponding 2D image. The training dataset includes the plurality of data items, the 2D depth map and the probability.","A method comprising:
receiving, by a processing device operatively coupled to memory, data comprising a plurality of data items, each data item of the plurality of data items comprising a three-dimensional (3D) radar heat map of an object and a corresponding two-dimensional (2D) image of the object captured by a stereo camera;
inputting, by the processing device, the plurality of data items into a machine learning model comprising a generative adversarial network (GAN) comprising:
a generator network that generates a 2D depth map for the object by encoding voxels within the 3D radar heat map into a first one-dimensional (1D) vector and decoding the first 1D vector into the 2D depth map, wherein the 2D depth map comprises pixels that each represent a respective distance from a respective location to a radar imaging sub-system; and
a discriminator network that generates, based on the 3D radar heat map and the 2D depth map, an output comprising a probability that the 2D depth map is the corresponding 2D image of the object; and
training, by the processing device, the machine learning model based on the plurality of data items to generate a trained machine learning model that iteratively learns, based on the probability, to generate an updated 2D depth map that approximates the corresponding 2D image more closely than the 2D depth map, wherein the training comprises at least one of: training the generator network to generate the 2D depth map or training the discriminator network to generate the output.
"
US20080240548,US11/729352,"Isosurfacial three-dimensional imaging system and method","An isosurfacial three-dimensional imaging system and method uses scanning electron microscopy for surface imaging of an assumed opaque object providing a series of tilt images for generating a sinogram of the object and a voxel data set for generating a three-dimensional image of the object having exterior surfaces some of which may be obscured so as to provide exterior three-dimensional surface imaging of objects including hidden surfaces normally obscured from stereographic view.","A system for generating a voxel data set representing an image of an object, the system comprising,
a tilter upon which is disposed the object for changing angular positions of the object,
an image generator for illuminating the object and detecting returns from the object, the image generator providing tilt images of the object for the respective angular positions, and
a processor for translating the tilt images into respective sinograms, for translating the sinograms into image slices, and for generating the voxel data set.
"
US8217937,US11/729352,"Isosurfacial three-dimensional imaging system and method","An isosurfacial three-dimensional imaging system and method uses scanning electron microscopy for surface imaging of an assumed opaque object providing a series of tilt images for generating a sinogram of the object and a voxel data set for generating a three-dimensional image of the object having exterior surfaces some of which may be obscured so as to provide exterior three-dimensional surface imaging of objects including hidden surfaces normally obscured from stereographic view.","A system for generating a voxel data set representing an image of an object, the system comprising,
a tilter upon which is disposed the object for changing angular positions of the object,
an image generator configured to:
illuminate the object
detect reflected returns from the object, and
generate tilt images of the object for the respective angular positions based on the reflected returns, and
a processor programmed
for generating transmissive approximations of the tilt images, wherein each transmissive approximation represents an assumed transmission density of a corresponding tilt image selected from the tilt images, wherein generating each transmissive approximation comprises inverting intensities of pixels making up the corresponding tilt image,
for translating the transmissive approximations of the tilt images into respective sinograms,
for translating the sinograms into image slices, and
for generating the voxel data set.
"
US20240112402,US17/957784,"Systems and methods for assessing trailer utilization","Systems and methods for assessing trailer utilization are disclosed herein. The method generates a trailer interior map and captures an image of the trailer interior. The map includes first voxels associated with the trailer interior and the image includes a plurality of three-dimensional (3D) image data points. The method generates a 3D map of an object based on a set of 3D points indicative of respective 3D image data points corresponding to respective first voxels and determines whether the object is non-conforming. The method determines at least one of second voxels associated with unusable space proximate to a non-conforming object, third voxels associated with the non-conforming object, and fourth voxels associated with a conforming object. The method determines an occupied portion of the trailer based on the first voxels, third voxels, and fourth voxels and trailer utilization based on the occupied portion of the trailer, the first voxels, and the second voxels.","A method for assessing trailer utilization, comprising:
generating a map of an interior of a trailer, the map including first voxels associated with the interior of the trailer;
capturing an image of the interior of the trailer, the image including a plurality of three-dimensional (3D) image data points;
iterating over each 3D image data point to generate a set of 3D points indicative of respective 3D image data points that correspond to respective first voxels;
generating a 3D map of an object based on the set of 3D points;
determining whether the object is non-conforming;
responsive to determining that the object is non-conforming, determining second voxels associated with unusable space proximate to the non-conforming object from among the first voxels and third voxels associated with the non-conforming object from among the first voxels;
responsive to determining that the object is not non-conforming, determining fourth voxels associated with the not non-conforming object from among the first voxels;
determining an occupied portion of the trailer based on the first voxels, the third voxels, and the fourth voxels;
filling at least one region associated with the non-conforming object based on dimension data of the non-conforming object;
determining trailer utilization based on the occupied portion of the trailer, the first voxels, and the second voxels; and
displaying, on a user interface, the trailer utilization for a user.
"
US12086934,US17/957784,"Systems and methods for assessing trailer utilization","Systems and methods for assessing trailer utilization are disclosed herein. The method generates a trailer interior map and captures an image of the trailer interior. The map includes first voxels associated with the trailer interior and the image includes a plurality of three-dimensional (3D) image data points. The method generates a 3D map of an object based on a set of 3D points indicative of respective 3D image data points corresponding to respective first voxels and determines whether the object is non-conforming. The method determines at least one of second voxels associated with unusable space proximate to a non-conforming object, third voxels associated with the non-conforming object, and fourth voxels associated with a conforming object. The method determines an occupied portion of the trailer based on the first voxels, third voxels, and fourth voxels and trailer utilization based on the occupied portion of the trailer, the first voxels, and the second voxels.","A method for assessing trailer utilization, comprising:
generating a map of an interior of a trailer, the map including first voxels associated with the interior of the trailer;
capturing an image of the interior of the trailer, the image including a plurality of three-dimensional (3D) image data points;
iterating over each 3D image data point to generate a set of 3D points indicative of respective 3D image data points that correspond to respective first voxels;
generating a 3D map of an object based on the set of 3D points;
determining whether the object is non-conforming;
responsive to determining that the object is non-conforming, determining second voxels associated with unusable space proximate to the non-conforming object from among the first voxels and third voxels associated with the non-conforming object from among the first voxels;
responsive to determining that the object is not non-conforming, determining fourth voxels associated with the not non-conforming object from among the first voxels;
determining an occupied portion of the trailer based on the first voxels, the third voxels, and the fourth voxels;
filling at least one region associated with the non-conforming object based on dimension data of the non-conforming object;
determining trailer utilization based on the occupied portion of the trailer, the first voxels, and the second voxels; and
displaying, on a user interface, the trailer utilization for a user.
"
US10748662,US15/949537,"Content-based medical image retrieval method and retrieval system","A content-based medical image retrieval method and a retrieval system using the same include: obtaining m (2≤m≤n) number of unit images from a three-dimensional (3D) medical image including n (n≥2) number of unit images and extracting features per unit image from each of the m (2≤m≤n) number of unit images through a feature extraction unit, wherein the 3D medical image is voxel data including a plurality of slices and each of the plurality of slices is defined as a unit image; inputting features of each unit image extracted from the m (2≤m≤n) number of unit images to a recurrent neural network to generate an output value; and performing medical image retrieval using the output value through an input processing unit, wherein a plurality of 3D medical images to be compared with the output value include a 3D medical image having p (p≥2, p≠n) number of unit images.","A content-based medical image retrieval method, comprising:
obtaining m (2mn) number of unit images from a three-dimensional (3D) current medical image including n (n2) number of unit images, wherein the 3D current medical image is in voxel data including a plurality of slices and each of the plurality of slices is defined as a unit image;
extracting features from each of the obtained m number of unit images through a feature extraction unit by segmenting specific regions in each of the obtained m number of unit images by diseases and quantifying each of the segmented specific regions;
inputting each of the features per unit image which are extracted from the m number of unit images to a neural network to generate a current output value, wherein the neural network is configured to derive the current output value using each of the features per unit image; and
performing medical image retrieval using the current output value through an input processing unit,
wherein a plurality of 3D reference medical images to be compared with the current output value include a 3D reference medical image having p (p2, pn) number of unit images,
wherein the features from each of the obtained m number of unit images are classified based on type of the disease.
"
US11100669,US16/534144,"Multimodal three-dimensional object detection","A method includes obtaining surface samples that represent three-dimensional locations of surfaces of an environment; generating a voxelized representation of the surfaces of the environment in three-dimensional space using the surface samples; obtaining an image that shows the surfaces of the environment; associating each of the surface samples with image information that corresponds to a portion of the image that is spatially correlated with a respective one of the surface samples; determining voxel features for voxels from the voxelized representation based on the surface samples and the image information using a first trained machine learning model, wherein the voxel features each describe three-dimensional shapes present within a respective one of the voxels; and detecting objects based on the voxel features.","A method, comprising:
obtaining surface samples that represent three-dimensional locations of surfaces of an environment;
generating a voxelized representation of the surfaces of the environment in three-dimensional space using the surface samples;
obtaining an image that shows the surfaces of the environment;
associating each of the surface samples with image information that corresponds to a portion of the image that is spatially correlated with a respective one of the surface samples;
determining voxel features for voxels from the voxelized representation based on the surface samples and the image information using a first trained machine learning model, wherein the voxel features each describe three-dimensional shapes present within a respective one of the voxels; and
detecting objects based on the voxel features.
"
US9760263,US14/191755,"Image processing device, image processing method, and stereoscopic image display device","According to an embodiment, an image processing device includes a receiver, a determiner, and a generator. The receiver is configured to receive a three-dimensional position in a coordinate system of three-dimensional data including an object. The determiner is configured to determine placement of a three-dimensional pointer having a first 3D shape and a second 3D shape positioned around the first 3D shape so that a position of the first 3D shape corresponds to the received three-dimensional position. The generator is configured to generate a stereoscopic image representing the three-dimensional pointer and the object.","An image processing device, comprising a processor configured to:
convert a three-dimensional position in a real space as indicated by a pointer into a three-dimensional position in a coordinate system of three-dimensional medical data including an object of a subject;
receive the three-dimensional position converted by the processor;
determine placement of a three-dimensional pointer having a first 3D shape and a second 3D shape positioned around the first 3D shape so that a position of the first 3D shape corresponds to the received three-dimensional position; and
generate a stereoscopic image representing the three-dimensional pointer and the object, wherein
the processor further changes a color of the three-dimensional pointer to a different color than a color indicated by a value of a voxel that is a part of the object corresponding to the received three-dimensional position.
"
US20080298659,US11/756454,"Systems and methods for processing medical image data to facilitate comparisons among groups of subjects","Systems and methods for processing medical image data with increased sensitivity to facilitate comparisons among groups of subjects are disclosed herein. In one embodiment, a method comprises receiving a first three-dimensional image comprising a plurality of voxels, reducing a regional trend within the three-dimensional image, computing a semivariogram for a region of interest, defining at least one block of spatially correlated voxels, calculating voxel weights for each voxel within the at least one block, and determining a block average count and variance for the at least one block.","A method for processing medical image data, the method comprising:
receiving a first three-dimensional image comprising a plurality of voxels;
reducing a regional trend within the three-dimensional image;
computing a semivariogram for a region of interest;
defining at least one block of spatially correlated voxels;
calculating voxel weights for each voxel within the at least one block; and
determining a block average count and variance for the at least one block.
"
US7961922,US11/756454,"Systems and methods for processing medical image data to facilitate comparisons among groups of subjects","Systems and methods for processing medical image data with increased sensitivity to facilitate comparisons among groups of subjects are disclosed herein. In one embodiment, a method comprises receiving a first three-dimensional image comprising a plurality of voxels, reducing a regional trend within the three-dimensional image, computing a semivariogram for a region of interest, defining at least one block of spatially correlated voxels, calculating voxel weights for each voxel within the at least one block, and determining a block average count and variance for the at least one block.","A method for processing medical image data, the method comprising:
receiving a first three-dimensional image comprising a plurality of voxels;
reducing a regional trend within the three-dimensional image;
computing, with a processing device, a semivariogram for a region of interest, comprising determining an extent of correlation among at least a subset of the plurality of voxels;
defining at least one block of spatially correlated voxels;
calculating, with the processing device, voxel weights for each voxel within the at least one block; and
determining a block average count and variance for the at least one block.
"
US9715761,US14/324891,"Real-time 3d computer vision processing engine for object recognition, reconstruction, and analysis","Methods and systems are described for generating a three-dimensional (3D) model of a fully-formed object represented in a noisy or partial scene. An image processing module of a computing device receives images captured by a sensor. The module generates partial 3D mesh models of physical objects in the scene based upon analysis of the images, and determines a location of at least one target object in the scene by comparing the images to one or more 3D reference models and extracting a 3D point cloud of the target object. The module matches the 3D point cloud of the target object to a selected 3D reference model based upon a similarity parameter, and detects one or more features of the target object. The module generates a fully formed 3D model of the target object using partial or noisy 3D points from the scene, extracts the detected features of the target object and features of the 3D reference models that correspond to the detected features, and calculates measurements of the detected features.","A computerized method for generating a fully-formed three-dimensional (3D) model of an object represented in a noisy or partial scene, the method comprising:
receiving, by an image processing module of a computing device, a plurality of images captured by a sensor coupled to the computing device, the images depicting a scene containing one or more physical objects;
generating, by the image processing module, partial 3D mesh models of the physical objects in the scene based upon analysis of the plurality of images, the generating comprising:
cleaning, by the image processing module, the plurality of images by removing artifacts caused by the sensor from the images;
capturing, by the image processing module, a depth map for each cleaned image and converting the depth map into a point cloud;
generating, by the image processing module, a 3D global model of the scene;
registering, by the image processing module, the point cloud for each image to the 3D global model;
updating, by the image processing module, the 3D global model after each registration of a point cloud; and
generating, by the image processing module, the partial 3D mesh models after registration of the point clouds;
determining, by the image processing module, a location of at least one target object in the scene by comparing the plurality of images to one or more 3D reference models and extracting a 3D point cloud of the target object;
matching, by the image processing module, the 3D point cloud of the target object to a selected 3D reference model based upon a similarity parameter;
detecting, by the image processing module, one or more features of the target object based upon the matching step;
generating, by the image processing module using the 3D reference model, a fully formed 3D model of the target object using partial or noisy 3D points extracted from the scene;
extracting, by the image processing module using the 3D reference model, the detected features of the target object and features of the 3D reference models that correspond to the detected features of the target object; and
calculating, by the image processing module using the 3D reference model, measurements of the detected features of the target object by comparing each of the detected features of the target object to the corresponding features of the 3D reference models.
"
US20090076387,US11/901675,"Gain optimization of volume images for medical diagnostic ultrasonic imaging","Tissue information is equalized by adaptively controlling gain and mapping input data to output data based on the gain in three-dimensional medical diagnostic imaging. A hypersurface is fit in three spatial dimensions to tissue information in input data. The hypersurface is used to adjust the gain so that input values are mapped to output values with more uniform soft tissue levels.","In a medical ultrasonic imaging system, a method for adaptively controlling gain, said method comprising:
identifying voxels of input volume data corresponding to soft tissue;
fitting a three-dimensional hypersurface to the voxels corresponding to soft tissue; and
adaptively varying a gain of the system based at least in part on the fitted hypersurface.
"
US20090096787,US12/100942,"Method and apparatus for processing three dimensional images, and recording medium having a program for processing three dimensional images recorded therein","A pseudo three dimensional image is generated, based on an aspect image and a mapping image generated from an original three dimensional image, using a volume rendering method. A mapping image that represents the functions of a subject is generated using first voxel data that constitute an original three dimensional medical image of the subject. An aspect image is generated using second voxel data that constitute an original three dimensional medical image of the subject. A position matching means causes positions within a heart represented by the mapping image to correspond to positions within a heart represented by the aspect image. An image generating means executes volume rendering based on degrees of opacity within the mapping image, to generate the pseudo three dimensional image.","An image processing apparatus, comprising:
mapping image generating means, for generating a mapping image that represents a portion of a subject, by employing a first voxel data set, which is a voxel data set of a three dimensional image that represents the subject with at least a degree of opacity designated to each pixel thereof;
aspect image generating means, for generating an aspect image that represents the aspect of a target which includes at least a portion of the subject from a second voxel data set of the three dimensional image that represents the subject; and
image generating means, for generating a pseudo three dimensional image, by matching each position within the mapping image and the aspect image and executing volume rendering based on the degrees of opacity within the mapping image.
"
US8497862,US12/100942,"Method and apparatus for processing three dimensional images, and recording medium having a program for processing three dimensional images recorded therein","A pseudo three dimensional image is generated, based on an aspect image and a mapping image generated from an original three dimensional image, using a volume rendering method. A mapping image that represents the functions of a subject is generated using first voxel data that constitute an original three dimensional medical image of the subject. An aspect image is generated using second voxel data that constitute an original three dimensional medical image of the subject. A position matching means causes positions within a heart represented by the mapping image to correspond to positions within a heart represented by the aspect image. An image generating means executes volume rendering based on degrees of opacity within the mapping image, to generate the pseudo three dimensional image.","An image processing apparatus, comprising:
mapping image generating means, for generating a mapping image M that represents a portion of a subject, by employing a first voxel data set, which is a voxel data set of a three dimensional image that represents the subject with a degree of opacity assigned to each voxel thereof;
aspect image generating means, for generating an aspect image S that represents the aspect of a target which includes at least a portion of the subject from a second voxel data set of the three dimensional image that represents the subject with a degree of opacity assigned to each voxel thereof; and
image generating means, for generating a pseudo three dimensional image, by matching the mapping image M and the aspect image S and executing volume rendering, wherein the image generating means executes volume rendering by:
setting an alpha value based on a degree of opacity m of each determined voxel vi of the mapping image, for performing alpha blending processing, wherein said determined voxels vi of the mapping image are determined as voxels vi of the mapping image which correspond to voxels vi of the aspect image which are to be used in volume rendering, and
obtaining a pseudo three dimensional image having pixel values C by blending the mapping image and the aspect image with formula (4):
 C =  i = 1 n  ( ( 1 -  m  ( v i  ) )  c s  ( v i ) +  m  ( v i  )  c m  ( v i  ) )   s  ( v i )   j = 1 i - 1   ( 1 -  s  ( v j ) ) ( 4 )  (see pdf for full equation)
wherein
cs are brightness values, and s are degree of opacity for each point vi of the aspect image to be used in volume rendering, and
cm are brightness values, and m are degree of opacity for each determined voxel vi of the mapping image,
wherein said obtaining comprises:
calculating, with respect to said each point to be used for the volume rendering, a blended brightness value with formula (4), by
performing alpha blending processing for each of said determined voxel vi of the mapping image, to obtain a calculated blended value, by applying said alpha values to:
the brightness values cm for each point vi of the mapping image to be used in volume rendering, and
the brightness values cs of the points vi in the aspect image to be used for the volume rendering, and
executing volume rendering with formula (4) based on the calculated blended value and the degree of opacity s assigned to each voxel vi of the aspect image used in volume rendering.
"
US20210225027,US17/222471,"Image region localization method, image region localization apparatus, and medical image processing device","Embodiments of this application disclose methods, systems, and devices for image region localization and medical image processing. In one aspect, a method comprises acquiring three-dimensional images of a target body part of a patient. The three-dimensional images comprise a plurality of magnetic resonant imaging (MRI) modalities. The method comprises registering a first image set of a first modality with a second image set of a second modality. After the registering, image features of the three-dimensional images are extracted. The image features are fused to obtain fused features. The method also comprises determining voxel types corresponding to voxels in the three-dimensional images according to the fused features. The method also comprises selecting, from the three-dimensional images, target voxels having a preset voxel type, obtaining position information of the target voxels, and localizing a target region within the target body part based on the position information of the target voxels.","An image region localization method, comprising:
acquiring a plurality of three-dimensional images of a target body part of a patient, the plurality of three-dimensional images comprising a plurality of magnetic resonant imaging (MRI) modalities, the plurality of three-dimensional images including a first three-dimensional image set of a first modality and a second three-dimensional image set of a second modality;
registering the first three-dimensional image set with the second three-dimensional image set;
after the registering, extracting image features of the plurality of three-dimensional images;
fusing the image features of the plurality of three-dimensional images;
in accordance with the fusing, obtaining fused features based on the image features;
determining voxel types corresponding to voxels in the three-dimensional images according to the fused features;
selecting, from the three-dimensional images, target voxels having a preset voxel type;
obtaining position information of the target voxels; and
localizing a target region within the target body part based on the position information of the target voxels.
"
US12067725,US17/222471,"Image region localization method, image region localization apparatus, and medical image processing device","Embodiments of this application disclose methods, systems, and devices for image region localization and medical image processing. In one aspect, a method comprises acquiring three-dimensional images of a target body part of a patient. The three-dimensional images comprise a plurality of magnetic resonant imaging (MRI) modalities. The method comprises registering a first image set of a first modality with a second image set of a second modality. After the registering, image features of the three-dimensional images are extracted. The image features are fused to obtain fused features. The method also comprises determining voxel types corresponding to voxels in the three-dimensional images according to the fused features. The method also comprises selecting, from the three-dimensional images, target voxels having a preset voxel type, obtaining position information of the target voxels, and localizing a target region within the target body part based on the position information of the target voxels.","An image region localization method, comprising:
acquiring a plurality of three-dimensional (3D) images of a target body part of a patient, the plurality of 3D images including a first 3D image set having a first magnetic resonant imaging (MRI) modality of a plurality of MRI modalities and a second 3D image set having a second MRI modality of the plurality of MRI modalities, wherein the first MRI modality is different from the second MRI modality and the plurality of MRI modalities are selected from the group consisting of Magnetic Resonance Angiography (MRA), diffusion weighted image (DWI), apparent diffusion coefficient (ADC), fat suppression (FS) imaging, and dynamic contrast-enhanced (DCE) imaging;
registering the first 3D image set having the first MRI modality with the second 3D image set having the second MRI modality so that images in the first 3D image set and images in the second 3D image set have the same image dimensions and the same coordinate system;
after the registering, extracting first image features from the first 3D image set having the first MRI modality and extracting second image features from the second 3D image set having the second MRI modality, wherein the first image features and the second image features are different image features;
fusing the extracted first and second image features to obtain fused features having multi-modality information based on the extracted first and second image features;
determining voxel types corresponding to voxels in the 3D images according to the fused features, each voxel type corresponding to a respective pathological type;
selecting, from the 3D images, target voxels having a preset voxel type corresponding to a predefined pathological type;
obtaining position information of the target voxels; and
localizing a target region within the target body part based on the position information of the target voxels.
"
US20210113167,US16/497764,"System and method for hierarchical multi-level feature image synthesis and representation","A method for processing breast tissue image data includes processing the image data to generate a set of image slices collectively depicting the patient's breast; for each image slice, applying one or more filters associated with a plurality of multi-level feature modules, each configured to represent and recognize an assigned characteristic or feature of a high-dimensional object; generating at each multi-level feature module a feature map depicting regions of the image slice having the assigned feature; combining the feature maps generated from the plurality of multi-level feature modules into a combined image object map indicating a probability that the high-dimensional object is present at a particular location of the image slice; and creating a 2D synthesized image identifying one or more high-dimensional objects based at least in part on object maps generated for a plurality of image slices.","A method for processing breast tissue image data, comprising:
processing image data of a patient's breast tissue to generate a set of image slices that collectively depict the patient's breast tissue;
applying one or more filters associated with a plurality of multi-level feature modules to each image slice of the set, wherein the multi-level feature modules are configured to recognize at least one assigned feature of a high-dimensional object that may be present in the patient's breast tissue;
at each multi-level feature module of the plurality, generating a feature map depicting regions in the respective image slice having the at least one assigned feature; and
combining the generated feature maps into an object map that indicates a probable location of the respective high-dimensional object.
"
US20220192615,US17/692989,"System and method for hierarchical multi-level feature image synthesis and representation","A method for processing breast tissue image data includes processing the image data to generate a set of image slices collectively depicting the patient's breast; for each image slice, applying one or more filters associated with a plurality of multi-level feature modules, each configured to represent and recognize an assigned characteristic or feature of a high-dimensional object; generating at each multi-level feature module a feature map depicting regions of the image slice having the assigned feature; combining the feature maps generated from the plurality of multi-level feature modules into a combined image object map indicating a probability that the high-dimensional object is present at a particular location of the image slice; and creating a 2D synthesized image identifying one or more high-dimensional objects based at least in part on object maps generated for a plurality of image slices.","A method for processing breast tissue image data, comprising:
processing image data of a patient's breast tissue to generate a set of image slices that collectively depict the patient's breast tissue;
applying one or more filters associated with a plurality of multi-level feature modules to each image slice of the set, wherein the multi-level feature modules are configured to recognize at least one assigned feature of a high-dimensional object that may be present in the patient's breast tissue;
at each multi-level feature module of the plurality, generating a feature map depicting regions in the respective image slice having the at least one assigned feature; and
combining the generated feature maps into an object map that indicates a probable location of the respective high-dimensional object.
"
US11399790,US16/497764,"System and method for hierarchical multi-level feature image synthesis and representation","A method for processing breast tissue image data includes processing the image data to generate a set of image slices collectively depicting the patient's breast; for each image slice, applying one or more filters associated with a plurality of multi-level feature modules, each configured to represent and recognize an assigned characteristic or feature of a high-dimensional object; generating at each multi-level feature module a feature map depicting regions of the image slice having the assigned feature; combining the feature maps generated from the plurality of multi-level feature modules into a combined image object map indicating a probability that the high-dimensional object is present at a particular location of the image slice; and creating a 2D synthesized image identifying one or more high-dimensional objects based at least in part on object maps generated for a plurality of image slices.","A method for processing breast tissue image data, comprising: processing image data of a patient's breast tissue to generate a set of image slices that collectively depict the patient's breast tissue;
applying one or more filters associated with a plurality of multi-level feature modules to each image slice of the set, wherein the multi-level feature modules are configured to recognize at least one assigned feature of a high-dimensional object that may be present in the patient's breast tissue;
at each multi-level feature module of the plurality, generating a feature map depicting regions in the respective image slice having the at least one assigned feature; and
combining the generated feature maps into an object map that indicates a probable location of the respective high-dimensional object, wherein the at least one feature of the high-dimensional object includes at least one of a low-level feature, a mid-level feature, and a high-level feature.
"
US20200203001,US16/628795,"Segmentation of medical images","Methods for segmenting medical images from different modalities include integrating a plurality of types of quantitative image descriptors with a deep 3D convolutional neural network. The descriptors include: (i) a Gibbs energy for a prelearned 7th-order Markov-Gibbs random field (MGRF) model of visual appearance, (ii) an adaptive shape prior model, and (iii) a first-order appearance model of the original volume to be segmented. The neural network fuses the computed descriptors to obtain the final voxel-wise probabilities of the goal regions.","A method for segmenting medical images comprising:
integrating image descriptors with a three dimensional neural network, the image descriptors including a medical image, a Gibbs energy for a Markov-Gibbs random field model of the medical image, and an adaptive shape prior model of the medical image;
generating, using the three dimensional neural network, probabilities for a goal region; and
designating, based on the generated probabilities, the goal region in the medical image.
"
US11875892,US16/628795,"Segmentation of medical images","Methods for segmenting medical images from different modalities include integrating a plurality of types of quantitative image descriptors with a deep 3D convolutional neural network. The descriptors include: (i) a Gibbs energy for a prelearned 7th-order Markov-Gibbs random field (MGRF) model of visual appearance, (ii) an adaptive shape prior model, and (iii) a first-order appearance model of the original volume to be segmented. The neural network fuses the computed descriptors to obtain the final voxel-wise probabilities of the goal regions.","A method for segmenting medical images comprising:
integrating image descriptors with a three-dimensional neural network, the image descriptors including a medical image, a Gibbs energy for a Markov-Gibbs random field model of the medical image, and an adaptive shape prior model of the medical image;
generating, using the three-dimensional neural network, probabilities for a goal region; and
designating, based on the generated probabilities, the goal region in the medical image.
"
US20200250829,US16/649237,"Automated tumor partitioning","The invention provides for a medical instrument (100, 300, 400) comprising: a memory (110) for storing machine executable instructions (112) and a processor (106) for controlling the medical instrument. Execution of the machine executable instructions cause the processor to: receive (200) three dimensional medical image data (114) descriptive of a subject (318), wherein the three dimensional medical image data comprises voxels; receive (202) a segmentation of the three dimensional medical image data, wherein the segmentation divides the three dimensional image data into non-tumor voxels (700) and tumor voxels (500); choose (204) a center point (118) of the tumor voxels; divide (206) the tumor voxels into multiple groups (120) using a set of orthogonal planes (502, 504, 600), wherein the center point is within each of the orthogonal planes; calculate (208) at least one group radiomic feature (122) selected from a set of radiomic features for each of the multiple voxel groups; compute (210) a statistical measure (124) for each of the at least one group radiomic feature; calculate (212) a scalar value (128) by calculating the sum of each statistical measure multiplied by a predetermined group weighting value (126), wherein the predetermined group weighting value is unique for each statistical measure; and provide (214) a signal using a signaling interface device (108, 402) if the scalar value is above a predetermined threshold (130).","A medical instrument comprising:
a memory for storing machine executable instructions;
a processor for controlling the medical instrument, wherein execution of the machine executable instructions cause the processor to:
receive three dimensional medical image data descriptive of a subject, wherein the three dimensional medical image data comprises voxels;
receive a segmentation of the three dimensional medical image data, wherein the segmentation divides the three dimensional image data into non-tumor voxels and tumor voxels;
choose a center point of the tumor voxels;
divide the tumor voxels into multiple groups using a set of orthogonal planes, wherein the center point is within each of the orthogonal planes;
calculate (208) at least one group radiomic feature selected from a set of radiomic features for each of the multiple voxel groups;
compute a statistical measure for each of the at least one group radiomic feature;
calculate a scalar value by calculating the sum of each statistical measure multiplied by a predetermined group weighting value, wherein the predetermined group weighting value is unique for each statistical measure; and
provide a signal using a signaling interface device if the scalar value is above a predetermined threshold.
"
US10997726,US16/649237,"Automated tumor partitioning","The invention provides for a medical instrument (100, 300, 400) comprising: a memory (110) for storing machine executable instructions (112) and a processor (106) for controlling the medical instrument. Execution of the machine executable instructions cause the processor to: receive (200) three dimensional medical image data (114) descriptive of a subject (318), wherein the three dimensional medical image data comprises voxels; receive (202) a segmentation of the three dimensional medical image data, wherein the segmentation divides the three dimensional image data into non-tumor voxels (700) and tumor voxels (500); choose (204) a center point (118) of the tumor voxels; divide (206) the tumor voxels into multiple groups (120) using a set of orthogonal planes (502, 504, 600), wherein the center point is within each of the orthogonal planes; calculate (208) at least one group radiomic feature (122) selected from a set of radiomic features for each of the multiple voxel groups; compute (210) a statistical measure (124) for each of the at least one group radiomic feature; calculate (212) a scalar value (128) by calculating the sum of each statistical measure multiplied by a predetermined group weighting value (126), wherein the predetermined group weighting value is unique for each statistical measure; and provide (214) a signal using a signaling interface device (108, 402) if the scalar value is above a predetermined threshold (130).","A medical instrument comprising:
a memory for storing machine executable instructions;
a processor for controlling the medical instrument, wherein execution of the machine executable instructions cause the processor to:
receive three dimensional medical image data descriptive of a subject, wherein the three dimensional medical image data comprises voxels;
receive a segmentation of the three dimensional medical image data, wherein the segmentation divides the three dimensional image data into non-tumor voxels and tumor voxels;
choose a center point of the tumor voxels;
divide the tumor voxels into multiple groups using a set of orthogonal planes, wherein the center point is within each of the orthogonal planes;
calculate (208) at least one group radiomic feature selected from a set of radiomic features for each of the multiple voxel groups;
compute a statistical measure for each of the at least one group radiomic feature;
calculate a scalar value by calculating the sum of each statistical measure multiplied by a predetermined group weighting value wherein the predetermined group weighting value is unique for each statistical measure; and
provide a signal using a signaling interface device if the scalar value is above a predetermined threshold.
"
US9775582,US14/729566,"Medical image photographing apparatus and method of processing medical image","Provided is a medical image photographing apparatus, including: an X-ray generator configured to radiate an X-ray toward an object that is located in a three-dimensional (3D) virtual grid space which includes a plurality of voxels; an X-ray detector comprising a plurality of detecting elements and configured to detect the X-ray that has propagated through the object; and an image processor configured to process projection image data corresponding to the detected X-ray based on a volume of a first region within the plurality of voxels, through which the X-ray propagates.","A medical image photographing apparatus comprising:
an X-ray generator configured to irradiate an X-ray toward an object that is located in a three-dimensional (3D) virtual grid space which includes a plurality of voxels;
an X-ray detector comprising a plurality of detecting elements and configured to detect the X-ray that has propagated through the object; and
an image processor configured to process projection image data corresponding to the detected X-ray based on a volume of a predefined first region within the plurality of voxels, through which the X-ray has propagated,
wherein the medical image photographing apparatus further comprises one from among a computed tomography (CT) apparatus, a C-arm medical image photographing apparatus, and a Positron Emission Tomography (PET)/CT apparatus, and
wherein the X-ray generator is further configured to irradiate the X-ray in a form of a cone-beam or a fan-beam, and
wherein the image processor is further configured to set a slice in the 3D virtual grid space and to acquire, as the first region, a region of an overlap between the slice and a first polyhedron formed by connecting a point from which the X-ray generator irradiates the X-ray to each of a plurality of vertices lying on a face of one of the plurality of detecting elements, the face being directed toward the X-ray generator.
"
US20250166216,US18/516590,"Multimodal 3d object detection using temporal and structure consistency in voxel feature space","An example device for detecting objects through processing of media data, such as image data and point cloud data, includes a processing system configured to form voxel representations of a real-world three-dimensional (3D) space using images and point clouds captured for the 3D space at consecutive time steps, extract image and/or point cloud features for voxels in voxel representations of the 3D space, determine correspondences between the voxels at consecutive time steps according to similarities between the extracted features, and determine positions of objects in the 3D space using the correspondences between the voxels. For example, the processing system may perform triangulation according to positions of a moving object to positions of the voxels at the time steps. In this manner, the processing system may generate an accurate bird's eye view (BEV) representation of the real-world 3D space.","A method of processing media data, the method comprising:
forming a first voxel representation of a three-dimensional space at a first time using a first image of the three-dimensional space captured by a camera of a moving object having a first pose and a first point cloud of the three-dimensional space captured by a sensor of the moving object;
determining a first set of features for voxels in the first voxel representation, the first set of features representing visual characteristics of the corresponding voxels;
forming a second voxel representation of the three-dimensional space at a second time using a second image of the three-dimensional space captured by the camera of the moving object having a second pose and a second point cloud of the three-dimensional space captured by the unit of the moving object;
determining a second set of features for voxels in the second voxel representation;
determining correspondences between the voxels in the first voxel representation and the voxels in the second voxel representation according to similarities between the first set of features and the second set of features; and
determining positions of objects in the three-dimensional space relative to the moving object according to the first pose, the second pose, and the correspondences between the voxels in the first voxel representation and the voxels in the second voxel representation, the objects being represented by the voxels in the first voxel representation and the voxels in the second voxel representation.
"
US20200357120,US16/938773,"Method and apparatus for predicting brain disease change through machine learning and program for the same","A method for predicting brain disease state change is disclosed. The method includes acquiring test images obtained by capturing a portion of a human brain at a time interval, performing a pre-processing procedure of converting the test images into test voxels configured to be processed for image analysis, wherein a respective test voxel of the test voxels is composed of three-dimensional voxel units, mapping first and second test voxels selected from the test voxels acquired from a patient, with each other on a three-dimensional voxel unit, wherein the first test voxel is acquired at a first time-point and the second test voxel is acquired at a second time-point, generating a voxel-based data-set based on the mapped first and second test voxels, extracting a change in the test voxels using a deep neural network, and generating a state change probability model based on the change in the test voxels.","A method for predicting brain disease state change, being performed by a brain disease prediction apparatus, the method comprising:
acquiring, by the brain disease prediction apparatus, a plurality of test images, which comprise images obtained by capturing at least a portion of a human brain at a predetermined time interval;
performing, by the brain disease prediction apparatus, a pre-processing procedure of converting the plurality of test images into test voxels configured to be processed for image analysis, wherein a respective test voxel of the test voxels is data composed of three-dimensional voxel units;
mapping, by the brain disease prediction apparatus, first and second test voxels selected from the test voxels acquired from a patient, with each other on a three-dimensional voxel unit, wherein the first test voxel is acquired at a first time-point and the second test voxel is acquired at a second time-point, in which a predetermined time has elapsed from the first time-point;
generating, by the brain disease prediction apparatus, a voxel-based data-set based on the mapped first and second test voxels;
extracting, by the brain disease prediction apparatus, a change in the test voxels by using a deep neural network; and
generating, by the brain disease prediction apparatus, a state change probability model based on the change in the test voxels.
"
US11842493,US16/938773,"Method and apparatus for predicting brain disease change through machine learning and program for the same","A method for predicting brain disease state change is disclosed. The method includes acquiring test images obtained by capturing a portion of a human brain at a time interval, performing a pre-processing procedure of converting the test images into test voxels configured to be processed for image analysis, wherein a respective test voxel of the test voxels is composed of three-dimensional voxel units, mapping first and second test voxels selected from the test voxels acquired from a patient, with each other on a three-dimensional voxel unit, wherein the first test voxel is acquired at a first time-point and the second test voxel is acquired at a second time-point, generating a voxel-based data-set based on the mapped first and second test voxels, extracting a change in the test voxels using a deep neural network, and generating a state change probability model based on the change in the test voxels.","A method for predicting brain disease state change, being performed by a brain disease prediction apparatus, the method comprising: acquiring, by the brain disease prediction apparatus, a plurality of test images, which comprise images obtained by capturing at least a portion of a human brain at a predetermined time interval; performing, by the brain disease prediction apparatus, a pre-processing procedure of converting the plurality of test images into test voxels configured to be processed for image analysis, wherein a respective test voxel of the test voxels is data composed of three-dimensional voxel units; mapping, by the brain disease prediction apparatus, first and second test voxels selected from the test voxels acquired from a patient, with each other on a three-dimensional voxel unit, wherein the first test voxel is acquired at a first time-point and the second test voxel is acquired at a second time-point, in which a predetermined time has elapsed from the first time-point; generating, by the brain disease prediction apparatus, a voxel-based data-set based on the mapped first and second test voxels; extracting, by the brain disease prediction apparatus, a change in the test voxels by using a deep neural network; and generating, by the brain disease prediction apparatus, a state change probability model based on the change in the test voxels, wherein the generating of the state change probability model further includes: excluding, by the brain disease prediction apparatus, at a predetermined percentage, among measurement values, one or more measurement values having a greater state change rate than a first threshold state change rate, and one or more measurement values having a lower state change rate than a second threshold state change rate.
"
US20220183760,US17/644335,"Systems and methods for generating a three-dimensional model of a joint from two-dimensional images","A method for modeling a joint before, during, and/or after a medical procedure includes receiving first imaging data capturing the joint from a first imaging perspective and second imaging data capturing the joint from a second imaging perspective that is different than the first imaging perspective, the first and second imaging data generated intraoperatively via a two-dimensional imaging modality, generating three-dimensional image data by back-projecting the first and second imaging data in three-dimensional space in accordance with a relative difference between the first and second imaging perspectives, generating a three-dimensional model of the joint based on processing the three-dimensional image data with a machine learning model trained on imaging data generated via at least a three-dimensional imaging modality, and displaying a visualization based on the three-dimensional model of the joint during the medical procedure.","A method for modeling at least a portion of a joint before, during and/or after a medical procedure, the method comprising:
receiving first imaging data capturing the at least a portion of the joint from a first imaging perspective and second imaging data capturing the at least a portion of the joint from a second imaging perspective that is different than the first imaging perspective, the first and second imaging data generated, e.g. intraoperatively, via a two-dimensional imaging modality;
generating three-dimensional image data by back-projecting the first and second imaging data in three-dimensional space in accordance with a relative difference between the first and second imaging perspectives;
generating a three-dimensional model of the at least a portion of the joint based on processing the three-dimensional image data with a machine learning model trained on imaging data generated via at least a three-dimensional imaging modality; and
displaying a visualization based on the three-dimensional model of the at least a portion of the joint during the medical procedure.
"
US12256996,US17/644335,"Systems and methods for generating a three-dimensional model of a joint from two-dimensional images","A method for modeling a joint before, during, and/or after a medical procedure includes receiving first imaging data capturing the joint from a first imaging perspective and second imaging data capturing the joint from a second imaging perspective that is different than the first imaging perspective, the first and second imaging data generated intraoperatively via a two-dimensional imaging modality, generating three-dimensional image data by back-projecting the first and second imaging data in three-dimensional space in accordance with a relative difference between the first and second imaging perspectives, generating a three-dimensional model of the joint based on processing the three-dimensional image data with a machine learning model trained on imaging data generated via at least a three-dimensional imaging modality, and displaying a visualization based on the three-dimensional model of the joint during the medical procedure.","A method for modeling at least a portion of a joint before, during and/or after a medical procedure, the method comprising:
receiving first imaging data capturing the at least a portion of the joint from a first imaging perspective and second imaging data capturing the at least a portion of the joint from a second imaging perspective that is different than the first imaging perspective, the first and second imaging data generated via a two-dimensional imaging modality;
generating three-dimensional image data by back-projecting the first and second imaging data in three-dimensional space in accordance with a relative difference between the first and second imaging perspectives;
generating a three-dimensional model of the at least a portion of the joint by:
generating a set of multi-class voxels by processing the three-dimensional image data with a machine learning model trained on imaging data generated via at least a three-dimensional imaging modality; and
generating the three-dimensional model of the at least a portion of the joint based on multi-class voxels of the set of multi-class voxels that correspond to at least one class associated with the at least a portion of the joint; and
displaying a visualization based on the three-dimensional model of the at least a portion of the joint during the medical procedure.
"
US20220130156,US17/571887,"Three-dimensional object detection and intelligent driving","Methods, apparatuses, devices, and computer-readable storage media for three-dimensional object detection and intelligent driving are provided. In one aspect, a method includes: obtaining voxelized point cloud data corresponding to a plurality of voxels by voxelizing three-dimensional point cloud data; obtaining first feature information of the voxels and one or more initial three-dimensional bounding boxes by performing feature extraction on the voxelized point cloud data; for each of a plurality of key points obtained by sampling the three-dimensional point cloud data, determining second feature information of the key point according to location information of the key point and the first feature information of the plurality of voxels; and determining a target three-dimensional bounding box including a three-dimensional object to be detected from the one or more initial three-dimensional bounding boxes according to the second feature information of the key point located in the one or more initial three-dimensional bounding boxes.","A computer-implemented method, comprising:
obtaining, by voxelizing three-dimensional point cloud data, voxelized point cloud data corresponding to a plurality of voxels;
obtaining, by performing feature extraction on the voxelized point cloud data, respective first feature information of the plurality of voxels and one or more initial three-dimensional bounding boxes;
for each of a plurality of key points obtained by sampling the three-dimensional point cloud data,
determining, according to location information of the key point and the respective first feature information of the plurality of voxels, second feature information of the key point; and
determining, according to the second feature information of the key point located in each of the one or more initial three-dimensional bounding boxes, a target three-dimensional bounding box from the one or more initial three-dimensional bounding boxes, wherein the target three-dimensional bounding box comprises a three-dimensional object to be detected.
"
US20110081061,US12/572571,"Medical image analysis system for anatomical images subject to deformation and related methods","A medical image analysis system is for first and second anatomical image data of a same body area and subject to deformation. The first and second anatomical image data includes respective first and second sets of voxels. The medical image analysis system includes a processor cooperating with a memory to generate a respective reach array for each voxel of the second anatomical image data, with each reach array being a subset of contiguous voxels. The processor also generates a cost array for each reach array, with each cost array based upon probabilities of voxels of the reach array matching voxels of the first anatomical image data. The processor may also solve each cost array using belief propagation to thereby generate a deformation vector array between the first and second anatomical image data.","A medical image analysis system for first and second anatomical image data of a same body area and subject to deformation, the first and second anatomical image data comprising respective first and second sets of voxels, the medical image analysis system comprising:
a memory; and
a processor cooperating with said memory and configured to
generate a respective reach array for each voxel of the second anatomical image data, each reach array comprising a subset of contiguous voxels,
generate a cost array for each reach array, each cost array based upon probabilities of voxels of the reach array matching voxels of the first anatomical image data, and
solve each cost array using belief propagation to thereby generate a deformation vector array between the first and second anatomical image data.
"
US20110172531,US12/976382,"Ultrasonic diagnosis apparatus, medical image processing apparatus, and medical image diagnosis apparatus","According to one embodiment, an ultrasonic diagnosis apparatus includes an ultrasonic probe, an ultrasonic transmission/reception unit, a volume data generating unit, a projected image generating unit, a two dimensional region-of-interest setting unit, a specifying unit, a calculation unit and a three-dimensional region-of-interest determination unit. The specifying unit specifies cells on rays which pass through the respective pixels in the 2D-ROI and are used to acquire a VR image. The calculation unit calculates the contribution degree of each cell based on the voxel value and opacity of each cell specified and calculates the average value of the contribution degrees of cells equal in distance from the screen of the VR image along the line-of-sight direction. The three-dimensional region-of-interest determination unit specifies the distances from the screen of the VR image which correspond to average contribution values exceeding the predetermined threshold and determines the position of the 3D-ROI in the volume data.","An ultrasonic diagnosis apparatus comprising:
an ultrasonic probe;
an ultrasonic transmission/reception unit configured to transmit an ultrasonic wave to an object and receive a reflected wave corresponding to the transmitted ultrasonic wave from the object via the ultrasonic probe and to generate a received signal based on the received reflected wave;
a volume data generating unit configured to generate volume data based on the received signal;
a projected image generating unit configured to generate a projected image based on the volume data and a predetermined line-of-sight direction;
a two-dimensional region-of-interest setting unit configured to set a two-dimensional region of interest on the projected image;
a specifying unit configured to specify a plurality of voxels based on pixels in the two-dimensional region of interest and the predetermined line-of-sight direction;
a calculation unit configured to calculate a contribution degree of each of the specified voxels which contributes to a value of the pixels in the two-dimensional region of interest based on a voxel value and opacity of each of the plurality of voxels; and
a three-dimensional region-of-interest determination unit configured to determine a position of a three-dimensional region of interest in the volume data based on the contribution degree.
"
US20110188715,US12/697785,"Automatic identification of image features","Automatic identification of image features is described. In an embodiment, a device automatically identifies organs in a medical image using a decision forest formed of a plurality of distinct, trained decision trees. An image element from the image is applied to each of the trained decision trees to obtain a probability of the image element representing a predefined class of organ. The probabilities from each of the decision trees are aggregated and used to assign an organ classification to the image element. In another embodiment, a method of training a decision tree to identify features in an image is provided. For a selected node in the decision tree, a training image is analyzed at a plurality of locations offset from a selected image element, and one of the offsets is selected based on the results of the analysis and stored in association with the node.","A device for automatically identifying organs in a medical image, comprising:
a communication interface arranged to receive the medical image;
at least one processor; and
a memory arranged to store a decision forest comprising a plurality of distinct trained decision trees, and arranged to store executable instructions configured to cause the processor to: select an image element from the medical image; apply the image element to each of the trained decision trees to obtain a plurality of probabilities of the image element representing one of a plurality of predefined classes of organ; and aggregate the probabilities from each of the trained decision trees and assign an organ classification to the image element in dependence thereon.
"
US8165370,US12/359719,"Medical image processing apparatus and medical image processing method","Main parts of an endoscope system of the present invention include a medical observation apparatus, a medical image processing apparatus, and a monitor. A CPU of the medical image processing apparatus is constituted by function units including a three-dimensional model estimating unit, a detection target area setting unit, a shape feature value calculating unit, a three-dimensional shape detecting unit, a threshold determining unit, and a polyp determining unit. Such a configuration enables to execute a process appropriately adapted to an observation state of a targeted two-dimensional image and to improve the detection accuracy in the detection of a lesion with locally elevated shape as compared to the past.","A medical image processing apparatus comprising:
a three-dimensional model estimating unit for estimating a three-dimensional model of a living tissue based on a two-dimensional image of an image of the living tissue in a body cavity, the two-dimensional image inputted from a medical image pickup apparatus;
a detection target area setting unit for setting a detection target area of a lesion with elevated shape in the three-dimensional model;
a shape feature value calculating unit for calculating shape feature values indicative of a state of the shape at each data point included in the detection target area;
a three-dimensional shape detecting unit for detecting a lesion area with locally elevated shape existing in the detection target area based on a threshold process with respect to the shape feature values; and
a threshold determining unit for determining thresholds applied in the three-dimensional shape detecting unit, wherein
the threshold determining unit determines the thresholds applied in the three-dimensional shape detecting unit based on coordinates in an axial direction perpendicular to the two-dimensional image of the detection target area.
"
US20200191971,US16/223068,"Method and system for vehicle detection using lidar","A vehicle detection method includes acquiring a three-dimensional (3D) image with a plurality of point clouds; mapping the 3D image onto a two-dimensional (2D) image; interpolating the 2D image according to a distance between a camera and a first point cloud of the plurality of point clouds; transforming the 3D image into a plurality of voxels, and extracting a plurality of 3D deep features and a plurality of 2D deep features according to the plurality of voxels; and determining a detection result according to a classification of the plurality of 3D deep features and the plurality of 2D deep features.","A vehicle detection method, comprising:
acquiring a three-dimensional (3D) image with a plurality of point clouds;
mapping the 3D image onto a two-dimensional (2D) image;
interpolating the 2D image according to a distance between a camera and a first point cloud of the plurality of point clouds;
transforming the 3D image into a plurality of voxels, and extracting a plurality of 3D deep features and a plurality of 2D deep features according to the plurality of voxels; and
determining a detection result according to a classification of the plurality of 3D deep features and the plurality of 2D deep features.
"
US20030113003,US09/683321,"Method and system for segmentation of medical images","A method and system for segmenting three-dimensional (3D) medical images containing an object of interest are provided. The method comprises generating a plurality of successive layers of fixed radius spheres about a circumference of a sphere containing at least one seed point placed within the object of interest when a plurality of respective voxels contained within the spheres exceed a selected threshold. The generation of the layers is repeated until no further voxels contained within an outer surface of each respective layer exceed the selected threshold or a stop seed point is encountered. The layers form a segmented representation of the object of interest.","A method for segmenting three-dimensional (3D) medical images containing an object of interest comprising: 
generating a plurality of successive layers of fixed radius spheres about a circumference of a sphere containing at least one seed point placed within the object of interest when a plurality of respective voxels contained within the spheres exceed a selected threshold; and, 
repeating generation of the layers until no further voxels contained within an outer surface of each respective layer exceed the selected threshold, the layers forming a segmented representation of the object of interest. 
"
US7583831,US11/349793,"System and method for using learned discriminative models to segment three dimensional colon image data","A system and method for using learned discriminative models to segment a border of an anatomical structure in a three dimensional (3D) image is disclosed. A discriminative probability model is computed for each voxel in the 3D image. Thresholding is performed on each discriminative probability model. One or more two dimensional (2D) slices of the thresholded 3D image along X-Y planes are obtained. Seed regions are selected in the 2D slices. Morphological region growing is performed on the selected seed regions. An initial 3D segmentation is obtained. Boundary evolution is performed on the initial 3D segmentation. The segmented anatomical structure is removed. in the original 3D image.","A method for using learned discriminative models to segment a border of an anatomical structure in a three dimensional (3D) image comprising the steps of:
computing a discriminative probability model for each voxel in the 3D image;
performing thresholding on each discriminative probability model;
obtaining one or more two dimensional (2D) slices of the thresholded 3D image along X-Y planes;
selecting seed regions in the 2D slices;
performing morphological region growing on the selected seed regions;
obtaining an initial 3D segmentation;
performing boundary evolution on the initial 3D segmentation; and
removing the segmented anatomical structure in the original 3D image.
"
US7639867,US10/913885,"Medical image generating apparatus and method, and program","An image processing apparatus acquires voxel data obtained by imaging an interior of a living body by a modality and generates a three-dimensional medical image by volume rendering using a ray casting method. The image processing apparatus generates the three-dimensional medical image wherein shade of a surface of an inner wall of an intestinal tract is clearly displayed and an abnormal region invasively developed in the interior of the inner wall is distinguishably displayed based on color information corresponding to voxel data placed at a position shifted from the surface by a predetermined distance.","A medical image generating apparatus that generates a three-dimensional medical image by a ray casting method in which volume data including voxel values obtained by imaging an interior of a living body is acquired to calculate a reflected light of a light ray with which the volume data is virtually irradiated, comprising:
a shading section that performs shading with an irradiation of the light ray at an arrival position and a next arrival position of the virtual light ray;
a shift position specifying section that specifies a shift position having a voxel value at the ray arrival position shifted from the arrival position of the virtual light ray, wherein the shift position is different from the next arrival position;
a color information obtaining section that obtains color information from a voxel value at the shift position;
a gradation information obtaining section that obtains gradation information of the arrival position; and
an image generating section that generates a three-dimensional medical image based at least on the color information obtained by the color information obtaining section at the shift position and gradation information obtained by the gradation information obtaining section for each arrival point thereby using the color information at the shift position and the gradation information at each arrival position to calculate the reflected light of a light ray.
"
US20050152591,US11/031729,"System and method for filtering a medical image","A three dimensional medical image filter computes a value at a given location of the image based upon the properties of a given 3 D region. The filter is defined by equations that are functions of the gradient and image values of neighboring locations. The equations determine the final value at the given location. The specific definitions of these equations determine the filter properties and may be adjusted for different applications.","A computer-implemented method for generating a response value for a given voxel within an image based on a function of gradients and gray-level values of surrounding voxels to the given voxel, the method comprising the steps of: 
a. computing angle, magnitude, and distance values of the gradients of the surrounding voxels; 
b. computing a value based on the angle, magnitude and distance values computed in (a) and the gray-level values of the surrounding voxels; 
c. combining the values from the surrounding voxels to arrive at a final response value. 
"
US20080212887,US11/913554,"Method for coding pixels or voxels of a digital image and a method for processing digital images","A method for coding pixels or voxels of a digital or digitalized two dimensional or three dimensional image, comprises the steps of: providing a digital image consisting in a two dimensional array of pixels or in a three dimensional array of voxels, each pixel or voxel being defined by at least one variable as its intensity in a grey scale image or the HSV (Hue, Saturation and Value) or the RGB values in a colour image; each pixel or voxel and for each target pixel or voxel a neighborhood being formed by a pixel or voxel windows comprising the said target pixel or voxel and a certain number of surrounding pixels or voxels for each target pixel or voxel generating a vector univocally associated to the said target pixel or voxel, the components of the said vectors being generated as a function of the values of the said target pixel or voxel and of each of the pixels or voxels of the said pixel or voxel window. The function of the values of the said target pixel or voxel and of each of the pixels or voxels of the said pixel or voxel window correspond to the characteristic parameters of the numerical matrix representing the pixels or voxels of the said window or of a transformation of the said numerical matrix. The invention relates also to an image processing method in which image data coded according to the above method are processed by means of a predictive algorithm as for example an artificial neural network.","Method for coding pixels or voxels of a digital or digitalized two dimensional or three dimensional image, comprising the steps of
a) providing a digital image consisting in a two dimensional array of pixels or in a three dimensional array of voxels, each pixel or voxel being defined by at least one variable as its intensity in a grey scale image or the HSV (Hue, Saturation and Value) or the RGB values in a colour image;
b) each pixel or voxel of the image being considered as a target pixel or voxel and for each target pixel or voxel a neighborhood being formed by a pixel or voxel windows comprising the said target pixel or voxel and a certain number of surrounding pixels or voxels;
c) for each target pixel or voxel generating a vector univocally associated to the said target pixel or voxel, the components of the said vectors being generated as a function of the values of the said target pixel or voxel and of each of the pixels or voxels of the said pixel or voxel window;
Characterized in that
the function of the values of the said target pixel or voxel and of each of the pixels or voxels of the said pixel or voxel window correspond to the characteristic parameters of the numerical matrix representing the pixels or voxels of the said window or of a transformation of the said numerical matrix.
"
US8116558,US12/096851,"Three-dimensional shape data position matching method and device","A three-dimensional shape data position matching method for measuring a static three-dimensional shape from a plurality of measuring positions, and for combining and position matching the distance data thereof, including: a data inputting step S1 for inputting, into a computer, coordinate values on a three-dimensional shape at a new measuring position; a model structuring step S4 for structuring an environment model that partitions a spatial region in which the three-dimensional shape exists, into a plurality of voxels formed from rectangular solids, of which the boundary surfaces are mutually perpendicular, and stores the positions of the individual voxels; a matching step S5 for setting and recording a representative point and an error distribution thereof, within the voxel corresponding to the coordinate value; a fine matching step S7 for position matching so as to minimize the summation of the distances between adjacent error distributions by rotating and translating a new measured data and error distribution, or rotating and translating an environment model for a new measuring position, relative to an environment model for a previous measuring position; and an outputting step for outputting, to an outputting device, the voxel position, the representative point, and the error distribution.","A three-dimensional shape data position matching method for measuring a static three-dimensional shape from a plurality of measuring positions, and for combining and position matching the distance data thereof, comprising:
a data inputting step for inputting, into a computer, coordinate values on a three-dimensional shape at a new measuring position;
a model structuring step for structuring an environment model that partitions a spatial region in which the three-dimensional shape exists, into a plurality of voxels formed from rectangular solids, of which the boundary surfaces are mutually perpendicular, and stores the positions of the individual voxels;
a matching step for setting and recording a representative point and an error distribution thereof, within the voxel corresponding to the coordinate value;
a fine matching step for position matching so as to minimize the summation of the distances between adjacent error distributions by rotating and translating a new measured data and error distribution, or rotating and translating an environment model for a new measuring position, relative to an environment model for a previous measuring position; and
an outputting step for outputting, to an outputting device, the positions of the individual voxels, the representative point, and the error distribution.
"
US20080130970,US11/944338,"System and method for feature score mapping and visualization of medical images","A system to collect and analyze medical image data is applicable for multi-modality medical imaging systems, such as x-ray, MRI, and the like. Medical image data is collected and analyzed to determine one or more regions of interest. A selected region of interest is further analyzed to determine morphological characteristics. A feature library, which may be in the form of a data base, is used to analyze the image on a pixel-by-pixel basis to determine the degree to which the region of interest matches selected morphological characteristics, such as shape or margin. The resultant data is used to generate a map indicating a continuum over which the region of interest matches the morphological characteristics. A display receives the map data and applies it to the video image to thereby provide the user with a visualization of the degree to which the region of interest matches the morphological characteristics.","A system comprising:
an input configured to receive medical image data, the medical image data including a region of interest;
a data storage structure to store the received medical image data;
a feature mapping processor configured to analyze the region of interest with respect to a plurality of morphological characteristics in each of a plurality of morphological categories, and to generate a morphological score indicative of a degree to which the region of interest matches the plurality of morphological characteristics in each of the plurality of morphological categories; and
a display to display the medical image data, including the region of interest, the display including visual data indicative of the morphological score.
"
US20210192762,US17/124637,"Neural network-based millimeter-wave imaging system","A method includes receiving data including a plurality of data items, each data item of the plurality of data items including a three-dimensional (3D) radar heat map of an object and a corresponding two-dimensional (2D) image of the object captured by a stereo camera, inputting the training dataset into a machine learning model including a neural network (NN) that generates, from the 3D radar heat map, a 2D depth map for the object and outputs a probability that the 2D depth map is the corresponding 2D image of the object, and training the machine learning model based on a training dataset to generate a trained machine learning model that iteratively learns to generate an updated 2D depth map that approximates the corresponding 2D image. The training dataset includes the plurality of data items, the 2D depth map and the probability.","A method comprising:
receiving, by a processing device operatively coupled to memory, data comprising a plurality of data items, each data item of the plurality of data items comprising a three-dimensional (3D) radar heat map of an object and a corresponding two-dimensional (2D) image of the object captured by a stereo camera;
inputting, by the processing device, the plurality of data items into a machine learning model comprising a neural network (NN) that generates, from the 3D radar heat map, a 2D depth map for the object and outputs a probability that the 2D depth map is the corresponding 2D image of the object, wherein the plurality of data items, the 2D depth map, and the probability are comprised within a training dataset; and
training, by the processing device, the machine learning model based on the training dataset to generate a trained machine learning model that iteratively learns to generate an updated 2D depth map that approximates the corresponding 2D image more closely than the 2D depth map.
"
US20210049397,US17/074629,"Semantic segmentation method and apparatus for three-dimensional image, terminal, and storage medium","A semantic segmentation method and apparatus for a three-dimensional image, and a storage medium are provided. The method includes: obtaining a three-dimensional image; slicing the three-dimensional image according to three directional planes, to obtain two-dimensional slice images of an x axis, two-dimensional slice images of a y axis, and two-dimensional slice images of a z axis; invoking a first segmentation model, a second segmentation model, and a third segmentation model to respectively perform semantic segmentation on the two-dimensional slice images of the x axis, the y axis, and the z axis, to obtain distribution probability maps of a target object on the three directional planes; and obtaining a three-dimensional distribution binary image of the target object by invoking an adaptive fusion model to perform three-dimensional fusion on the three distribution probability maps respectively corresponding to an x-axis directional plane, a y-axis directional plane, and a z-axis directional plane.","A semantic segmentation method for a three-dimensional image performed by a terminal, comprising:
obtaining a three-dimensional image;
slicing the three-dimensional image according to three directional planes in which three-dimensional coordinate axes are located, to obtain two-dimensional slice images of an x axis, two-dimensional slice images of a y axis, and two-dimensional slice images of a z axis;
invoking a first segmentation model to perform semantic segmentation on the two-dimensional slice images of the x axis, to obtain a distribution probability map of a target object on an x-axis directional plane;
invoking a second segmentation model to perform semantic segmentation on the two-dimensional slice images of they axis, to obtain a distribution probability map of the target object on a y-axis directional plane;
invoking a third segmentation model to perform semantic segmentation on the two-dimensional slice images of the z axis, to obtain a distribution probability map of the target object on a z-axis directional plane; and
obtaining a three-dimensional distribution binary image of the target object by invoking an adaptive fusion model to perform three-dimensional fusion on the three distribution probability maps respectively corresponding to the x-axis directional plane, the y-axis directional plane, and the z-axis directional plane.
"
US11861501,US17/074629,"Semantic segmentation method and apparatus for three-dimensional image, terminal, and storage medium","A semantic segmentation method and apparatus for a three-dimensional image, and a storage medium are provided. The method includes: obtaining a three-dimensional image; slicing the three-dimensional image according to three directional planes, to obtain two-dimensional slice images of an x axis, two-dimensional slice images of a y axis, and two-dimensional slice images of a z axis; invoking a first segmentation model, a second segmentation model, and a third segmentation model to respectively perform semantic segmentation on the two-dimensional slice images of the x axis, the y axis, and the z axis, to obtain distribution probability maps of a target object on the three directional planes; and obtaining a three-dimensional distribution binary image of the target object by invoking an adaptive fusion model to perform three-dimensional fusion on the three distribution probability maps respectively corresponding to an x-axis directional plane, a y-axis directional plane, and a z-axis directional plane.","A semantic segmentation method for a three-dimensional image performed by a terminal, comprising:
obtaining a three-dimensional image;
slicing the three-dimensional image according to three directional planes in which three-dimensional coordinate axes are located, to obtain two-dimensional slice images of an x axis, two-dimensional slice images of a y axis, and two-dimensional slice images of a z axis;
invoking a first segmentation model to perform semantic segmentation on the two-dimensional slice images of the x axis, to obtain a distribution probability map of a target object on an x-axis directional plane;
invoking a second segmentation model to perform semantic segmentation on the two-dimensional slice images of they axis, to obtain a distribution probability map of the target object on a y-axis directional plane;
invoking a third segmentation model to perform semantic segmentation on the two-dimensional slice images of the z axis, to obtain a distribution probability map of the target object on a z-axis directional plane;
invoking an adaptive fusion model to combine the three distribution probability maps respectively corresponding to the x-axis directional plane, the y-axis directional plane, and the z-axis directional plane, to obtain a three-dimensional distribution feature map;
performing three-dimensional fusion convolution on the three-dimensional distribution feature map, to obtain a three-dimensional segmentation probability map;
obtaining a three-dimensional distribution binary image of the target object through calculation according to maximum probability categories of pixels in the three-dimensional segmentation probability map; and
filtering out noise pixels in the three-dimensional distribution binary image based on prior knowledge, the prior knowledge being obtained by collecting statistics on a distribution location of the target object in sample three-dimensional images.
"
US20100303358,US12/786853,"Method for the automatic analysis of image data of a structure","A method is described for the automatic analysis of image data of a structure. in at least one embodiment, the method includes: providing image data in the form of a three-dimensional voxel array, performing segmentation of the voxel array in order to determine a voxel subset, performing feature extraction at least for particular voxels of the voxel subset in order to generate a feature map, generating a scalar difference map on the basis of the feature map, performing classification with the aid of the difference map and identifying a structural anomaly in the image data on the basis of a classification result. A method for driving an image display device, an image processing system and an imaging system are furthermore described.","A method for the automatic analysis of image data of a structure, comprising:
providing image data in the form of a three-dimensional voxel array;
performing segmentation of the voxel array to determine a voxel subset;
performing feature extraction at least for particular voxels of the voxel subset to generate a feature map;
generating a scalar difference map on the basis of the feature map;
performing classification with the aid of the scalar difference map; and
identifying a structural anomaly in the image data on the basis of a classification result.
"
